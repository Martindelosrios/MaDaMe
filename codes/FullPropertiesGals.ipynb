{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Importing the needed libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import argparse\n",
    "import requests\n",
    "import contextlib\n",
    "from tqdm import tqdm\n",
    "import tempfile\n",
    "import h5py\n",
    "import atexit\n",
    "import numpy as np\n",
    "import subprocess\n",
    "#from illustris_python.groupcat import loadSingle, loadHeader\n",
    "#import illustris_python as il\n",
    "import matplotlib.pyplot as plt\n",
    "import mpl_toolkits.mplot3d as mpl3\n",
    "from numpy.linalg import eig\n",
    "from numpy.linalg import eigh\n",
    "from scipy.optimize import curve_fit, root\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "from scipy.stats import binned_statistic\n",
    "from matplotlib.gridspec import GridSpec\n",
    "\n",
    "from multiprocessing import Pool, current_process\n",
    "from itertools import product\n",
    "\n",
    "\n",
    "G     = 4.3e-6 # Grav. constant [kPc/M_{sun} (km/s)^2]\n",
    "H0    = 67.74 # Hubble Constant [km/s / Mpc]\n",
    "h     = H0 / 100 \n",
    "rho_c = 3*(H0**2)/(8*np.pi*G*1e-3) # Critical density [M_{sun}/Mpc**3]\n",
    "rho_c = rho_c * (1e-3 ** 3) #2.7754 * 1e2 * (H0/100)**2 # Critical density [M_{sun}/Kpc**3]\n",
    "Nfields = 9\n",
    "M_dm    = 7.5e6 # M_sun\n",
    "headers = {\"api-key\": '81b7c70637fa8b110e6b9f236ea07c37'}\n",
    "box_size = 75 * 1e3 / h # kpc\n",
    "a = 1 # scale factor\n",
    "z = 0 # Redshift\n",
    "\n",
    "R_bins = np.geomspace(1, 100, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotate(particles, velocities, theta = np.pi/2, rot_mat = None):\n",
    "    '''\n",
    "    Rotation in the y-axis\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    particles: np.array with shape (N,3) containing the coordinates of\n",
    "        the particles that will be rotated.\n",
    "        \n",
    "    velocities: np.array with shape (N,3) containing the velocities of\n",
    "        the particles that will be rotated.\n",
    "\n",
    "    theta: float. Angle that will be rotated around y-axis. Default = np.pi/2\n",
    "\n",
    "    rot_mat: (optional) Rotation matrix to be used. It can be any rotation matrix,\n",
    "        no need to be around y-axis. Default = None\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "\n",
    "    particles_rot:np.array shape (N,3) with the rotated coordinates.\n",
    "    \n",
    "    velocities_rot:np.array shape (N,3) with the rotated velocities.    \n",
    "    '''\n",
    "    \n",
    "    if rot_mat is None:\n",
    "        rot_mat = np.array([\n",
    "            [np.cos(theta), 0, np.sin(theta)],\n",
    "            [0, 1, 0],\n",
    "            [-np.sin(theta), 0, np.cos(theta)]\n",
    "        ])\n",
    "    particles_rot = particles @ rot_mat\n",
    "    velocities_rot = velocities @ rot_mat\n",
    "    return particles_rot, velocities_rot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "stars_old_header = ' Stellar particles for IllustrisTNG 100-1 \\n SKIRT 9 import format for a particle source with the Bruzual Charlot SED family \\n Column 1: x-coordinate (kpc) \\n Column 2: y-coordinate (kpc) \\n Column 3: z-coordinate (kpc) \\n Column 4: particle smoothing length (kpc) \\n Column 5: x-velocity (km/s) \\n Column 6: y-velocity (km/s) \\n Column 7: z-velocity (km/s) \\n Column 8: initial mass (Msun) \\n Column 9: metallicity (1) \\n Column 10: age (Gyr) \\n'\n",
    "stars_sb_header = ' Stellar particles for IllustrisTNG 100-1 \\n SKIRT 9 import format for a particle source with the Bruzual Charlot SED family \\n Column 1: x-coordinate (kpc) \\n Column 2: y-coordinate (kpc) \\n Column 3: z-coordinate (kpc) \\n Column 4: particle smoothing length (kpc) \\n Column 5: x-velocity (km/s) \\n Column 6: y-velocity (km/s) \\n Column 7: z-velocity (km/s) \\n Column 8: star formation rate (Msun/yr) \\n Column 9: metallicity (1) \\n Column 10: compactness (1) \\n Column 11: pressure (K/m3) \\n Column 12: cloud covering fraction (1) \\n'\n",
    "gas_header = ' Gas particles for IllustrisTNG 100-1 \\n SKIRT 9 import format for a medium source using M_dust = f_dust x Z x M_gas \\n Column 1: x-coordinate (kpc) \\n Column 2: y-coordinate (kpc) \\n Column 3: z-coordinate (kpc) \\n Column 4: gas mass volume density (Msun/pc3) \\n Column 5: metallicity (1) \\n Column 6: x-velocity (km/s) \\n Column 7: y-velocity (km/s) \\n Column 8: z-velocity (km/s) \\n '\n",
    "\n",
    "n_px     = 128 # Number of pixels\n",
    "D        = 15 # Distance to galaxy [Mpc]\n",
    "FoV      = 17.2 # Field of view [minutes]\n",
    "px_s     = 17.2 / n_px # Pixel size [minutes] \n",
    "FoV_phys = FoV * (1/60) * (np.pi / 180) * D * 1e6 # physical distance at observer [Pc]\n",
    "Rmax     = int(0.5 * n_px * D * 1e3 * px_s * 4.848e-6)\n",
    "Rframe   = Rmax * 1e3 # [Pc]\n",
    "Rmedium  = FoV_phys\n",
    "Rgrid    = 0.5 * Rframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import martini\n",
    "from martini.sources import TNGSource, SPHSource\n",
    "from martini import DataCube, Martini\n",
    "from martini.beams import GaussianBeam\n",
    "from martini.noise import GaussianNoise\n",
    "from martini.spectral_models import GaussianSpectrum\n",
    "from martini.sph_kernels import CubicSplineKernel, find_fwhm\n",
    "import astropy.units as U\n",
    "from Hdecompose.atomic_frac import atomic_frac\n",
    "\n",
    "from astropy.io import fits\n",
    "from astropy.wcs import WCS\n",
    "import astropy.units as U\n",
    "import astropy.constants as C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import illustris_python as il\n",
    "import pts.simulation as sm\n",
    "import pts.utils as ut\n",
    "import pts.visual as vis\n",
    "import pts.band as bd\n",
    "import pts.do"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "SDSS_U = bd.BroadBand('/u/m/mdelosri/SKIRT/resources/SKIRT9_Resources_Core/Band/SLOAN_SDSS_U_BroadBand.stab')\n",
    "SDSS_G = bd.BroadBand('/u/m/mdelosri/SKIRT/resources/SKIRT9_Resources_Core/Band/SLOAN_SDSS_G_BroadBand.stab')\n",
    "SDSS_R = bd.BroadBand('/u/m/mdelosri/SKIRT/resources/SKIRT9_Resources_Core/Band/SLOAN_SDSS_R_BroadBand.stab')\n",
    "SDSS_I = bd.BroadBand('/u/m/mdelosri/SKIRT/resources/SKIRT9_Resources_Core/Band/SLOAN_SDSS_I_BroadBand.stab')\n",
    "SDSS_Z = bd.BroadBand('/u/m/mdelosri/SKIRT/resources/SKIRT9_Resources_Core/Band/SLOAN_SDSS_Z_BroadBand.stab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This rotation is to have the same \"sky plane\" in martini than in skirt\n",
    "theta = np.pi/2\n",
    "# We have to perform this rotation to have the same sky plane in both codes\n",
    "rot_mat_martini = np.array([\n",
    "            [np.cos(theta), 0, np.sin(theta)],\n",
    "            [0, 1, 0],\n",
    "            [-np.sin(theta), 0, np.cos(theta)]\n",
    "                ])\n",
    "\n",
    "beam = GaussianBeam(\n",
    "    bmaj = 30.0 * U.arcsec, bmin=30.0 * U.arcsec, bpa=0.0 * U.deg, truncate=3.0\n",
    ")\n",
    "\n",
    "noise = GaussianNoise(\n",
    "    rms = 3.0e-8 * U.Jy * U.beam**-1\n",
    ")\n",
    "\n",
    "spectral_model = GaussianSpectrum(sigma = \"thermal\")\n",
    "\n",
    "sph_kernel = CubicSplineKernel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Some custom functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get(path, params=None, folderName=''):\n",
    "    '''\n",
    "    Illustris function\n",
    "    '''\n",
    "    # make HTTP GET request to path\n",
    "    r = requests.get(path, params=params, headers=headers)\n",
    "\n",
    "    # raise exception if response code is not HTTP SUCCESS (200)\n",
    "    r.raise_for_status()\n",
    "\n",
    "    if r.headers['content-type'] == 'application/json':\n",
    "        return r.json() # parse json responses automatically\n",
    "\n",
    "    if 'content-disposition' in r.headers:\n",
    "        filename = r.headers['content-disposition'].split(\"filename=\")[1]\n",
    "        if filename.endswith('.hdf5'):\n",
    "            file_access_property_list = h5py.h5p.create(h5py.h5p.FILE_ACCESS)\n",
    "            file_access_property_list.set_fapl_core(backing_store=False)\n",
    "            file_access_property_list.set_file_image(r.content)\n",
    "            \n",
    "            file_id_args = {\n",
    "                'fapl': file_access_property_list,\n",
    "                'flags': h5py.h5f.ACC_RDONLY,\n",
    "                'name': next(tempfile._get_candidate_names()).encode()\n",
    "            }\n",
    "            \n",
    "            h5_file_args = {'backing_store': False, 'driver': 'core', 'mode': 'r'}\n",
    "            with contextlib.closing(h5py.h5f.open(**file_id_args)) as file_id:\n",
    "                with h5py.File(file_id, **h5_file_args) as h5_file:\n",
    "                    #return np.array(h5_file['grid'])\n",
    "                    if 'grid' in h5_file.keys(): return np.array(h5_file['grid'])\n",
    "                    else:\n",
    "                        results = []\n",
    "                        for k in h5_file.keys():\n",
    "                            for sk in h5_file[k].keys():\n",
    "                                results.append(np.array(h5_file[k][sk]))\n",
    "                        return results\n",
    "        else:\n",
    "            with open(folderName + filename, 'wb') as f:\n",
    "                f.write(r.content)\n",
    "            return filename # return the filename string\n",
    "    return r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get1(path, name, params=None):\n",
    "    '''\n",
    "    Illustris function\n",
    "    '''\n",
    "    # make HTTP GET request to path\n",
    "    headers = {\"api-key\":\"81b7c70637fa8b110e6b9f236ea07c37\"}\n",
    "    r = requests.get(path, params=params, headers=headers)\n",
    "    # raise exception if response code is not HTTP SUCCESS (200)\n",
    "    r.raise_for_status()\n",
    "    if r.headers['content-type'] == 'application/json':\n",
    "        return r.json() # parse json responses automatically\n",
    "    if 'content-disposition' in r.headers:\n",
    "        filename = r.headers['content-disposition'].split(\"filename=\")[1]\n",
    "        with open(name + '.hdf5', 'wb') as f:\n",
    "            f.write(r.content)\n",
    "        return name + '.hdf5' # return the filename string\n",
    "    return NULL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mass_profile(gid, center):\n",
    "    '''\n",
    "    MIHAEL FUNCTION: compute the dark matter mass enclosed in 20 radii\n",
    "    from 1 to 100 kPc\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    gid : int \n",
    "        GroupID\n",
    "    center : list\n",
    "        (x,y,z) Position of the group\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    \n",
    "    NP Array\n",
    "        Array with the dark matter mass enclosed in 20 radii from 1 to 100 kPc\n",
    "    '''\n",
    "    dm = il.snapshot.loadHalo('/home/tnguser/sims.TNG/TNG100-1/output/', 99, gid, 'dm', fields=['Coordinates'])\n",
    "    dm = np.where(dm > 32500, dm - 75000, dm)\n",
    "    dm = np.where(dm < -32500, dm + 75000, dm)\n",
    "    center = np.where(center > 32500, center - 75000, center)\n",
    "    center = np.where(center < -32500, center + 75000, center)\n",
    "    dm = dm - center\n",
    "    dist = []\n",
    "    for d in dm:\n",
    "        D = np.sqrt(sum([c**2 for c in d]))\n",
    "        if D < 100: dist.append(D)\n",
    "    R_bins = np.geomspace(1, 100, 20)\n",
    "    M = np.array([len(np.where(np.array(dist) < R)[0]) * M_dm for R in R_bins])\n",
    "    return M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_total_mass_profile(Rmax, Rmin, Nm, sub_meta, url):\n",
    "    '''\n",
    "    Computes the dark matter, stars and gas mass enclosed in Nm radii\n",
    "    from Rmin to Rmax kPc\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    Rmin, Rmax : float \n",
    "        Min and Max radii\n",
    "    Nm : int\n",
    "        Number of radial bins\n",
    "    sub_meta : str\n",
    "        Illustris information of the subhalo\n",
    "    url : str\n",
    "        Url to the Illustris server\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    \n",
    "    List\n",
    "        List of 4 Arrays corresponding to the radial bins and the \n",
    "        dark matter, stars and gas mass enclosed in Nm radii from \n",
    "        Rmin to Rmax kPc\n",
    "    '''\n",
    "    center = np.array([sub_meta['pos_x'], sub_meta['pos_y'], sub_meta['pos_z']])\n",
    "    particles  = get(url + 'cutout.hdf5', {'dm':'Coordinates',\n",
    "                                                'gas':'Coordinates,Masses',\n",
    "                                                'stars':'Coordinates,Masses'\n",
    "                                               })\n",
    "    \n",
    "    dm = particles[2] - center\n",
    "    dm = np.where(dm > 32500, dm - 75000, dm)\n",
    "    dm = np.where(dm < -32500, dm + 75000, dm)\n",
    "    \n",
    "    dist_dm = []\n",
    "    for d in dm:\n",
    "        D = np.sqrt(sum([c**2 for c in d]))\n",
    "        dist_dm.append(D)\n",
    "    \n",
    "    m_gas = particles[1] * 1e10/h\n",
    "    gas = particles[0] - center\n",
    "    gas = np.where(gas > 32500, gas - 75000, gas)\n",
    "    gas = np.where(gas < -32500, gas + 75000, gas)\n",
    "    \n",
    "    dist_gas = []\n",
    "    for d in gas:\n",
    "        D = np.sqrt(sum([c**2 for c in d]))\n",
    "        dist_gas.append(D)\n",
    "\n",
    "    m_stars = particles[4] * 1e10/h\n",
    "    stars = particles[3] - center\n",
    "    stars = np.where(stars > 32500, stars - 75000, stars)\n",
    "    stars = np.where(stars < -32500, stars + 75000, stars)\n",
    "    \n",
    "    dist_stars = []\n",
    "    for d in stars:\n",
    "        D = np.sqrt(sum([c**2 for c in d]))\n",
    "        dist_stars.append(D)\n",
    "            \n",
    "    R_bins = np.geomspace(Rmin, Rmax, Nm)\n",
    "    \n",
    "    p_dm    = np.array([len(np.where(np.array(dist_dm) < R)[0]) * M_dm for R in R_bins])\n",
    "    p_stars = np.array([sum(m_stars[np.where(np.array(dist_stars) < R)[0]]) for R in R_bins])\n",
    "    p_gas   = np.array([sum(m_gas[np.where(np.array(dist_gas) < R)[0]]) for R in R_bins])\n",
    "    return R_bins, p_dm, p_stars, p_gas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_rot_mat_inertia(subhalo_pos, coordinates, masses, Rmin=0, Rmax=20):\n",
    "    '''\n",
    "    MIHAEL FUNCTION: computes the intertia momenta of a subhalo with ID sid\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    \n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    \n",
    "    Matrix\n",
    "        Rotation matrix for align the intertia momenta with the z-axis\n",
    "    '''\n",
    "    \n",
    "    coordinates = coordinates - subhalo_pos # Let's center the particles\n",
    "    dist = np.linalg.norm(coordinates, axis=1)\n",
    "    indices1 = np.argwhere(dist < Rmin)\n",
    "    indices2 = np.argwhere(dist > Rmax)\n",
    "    indices = np.concatenate((indices1, indices2))\n",
    "    distances = np.delete(dist, indices)\n",
    "    coordinates = np.delete(coordinates, indices, axis=0)\n",
    "    masses = np.delete(masses, indices)\n",
    "    \n",
    "    I = np.zeros((3,3))\n",
    "    for i in range(3):\n",
    "        for j in range(3):\n",
    "            if i == j: I[i][j] = np.sum(masses * (distances**2 - coordinates[:,i] * coordinates[:,j]))\n",
    "            else: I[i][j] = np.sum(masses * (- coordinates[:,i] * coordinates[:,j]))\n",
    "    \n",
    "    I_eign = np.linalg.eigh(I)\n",
    "    L = I_eign[1][2]\n",
    "    #print(I)\n",
    "    #print(L / np.linalg.norm(L))\n",
    "    \n",
    "    rot, _ = R.align_vectors([L, np.cross(L, [1,0,0])], [[0,0,1],[0,1,0]])\n",
    "    return rot.as_matrix(), L\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_rot_mat_angMom(subhalo_pos, coordinates, velocities, masses, Rmin = 0, Rmax = 20):\n",
    "    '''\n",
    "    Compute the angular momenta and return a rotation matrix that align the angular\n",
    "        momenta with the z-axis\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    subhalo_pos: np.array with shape (1,3) containing the position of the subhalo. \n",
    "        This will be used to center the particles.\n",
    "\n",
    "    coordinates: np.array with shape (N,3) containing the coordinates of\n",
    "        the particles that will be analysed.\n",
    "        \n",
    "    velocities: np.array with shape (N,3) containing the velocities of\n",
    "        the particles that will be analysed.\n",
    "        \n",
    "    masses: np.array with shape (N) containing the masses of the particles that will be analysed.\n",
    "\n",
    "    Rmin:  float. Particles at a distance to the subhalo below Rmin will not be considered for\n",
    "        the computation of the angular momenta.\n",
    "        \n",
    "    Rmax:  float. Particles at a distance to the subhalo above Rmax will not be considered for\n",
    "        the computation of the angular momenta.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "\n",
    "    np.array shape (3,3) with the rotation matrix needed for align the angular momenta\n",
    "        with the z-axis.\n",
    "    \n",
    "    np.array shape (3) wiht the angular momenta vector in the original coordinates.    \n",
    "    '''\n",
    "    \n",
    "    coordinates = coordinates - subhalo_pos # Let's center the particles\n",
    "    \n",
    "    dist = np.linalg.norm(coordinates, axis=1)\n",
    "    indices1 = np.argwhere(dist < Rmin)\n",
    "    indices2 = np.argwhere(dist > Rmax)\n",
    "    indices = np.concatenate((indices1, indices2))\n",
    "    distances = np.delete(dist, indices)\n",
    "    \n",
    "    coordinates = np.delete(coordinates, indices, axis = 0)\n",
    "    masses = np.delete(masses, indices)\n",
    "    velocities = np.delete(velocities, indices, axis = 0)\n",
    "    \n",
    "    L = (np.cross(coordinates, velocities).T * np.array(masses)).T\n",
    "    Lmean = np.mean(L, axis=0)\n",
    "    #print(Lmean / np.linalg.norm(Lmean))\n",
    "    \n",
    "    rot, _ = R.align_vectors([Lmean, np.cross(Lmean, [1,0,0])], [[0,0,1],[1,0,0]])\n",
    "    return rot.as_matrix(), Lmean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.patches import FancyArrowPatch\n",
    "from mpl_toolkits.mplot3d.axes3d import Axes3D\n",
    "from mpl_toolkits.mplot3d.proj3d import proj_transform\n",
    "\n",
    "class Arrow3D(FancyArrowPatch):\n",
    "\n",
    "    def __init__(self, x, y, z, dx, dy, dz, *args, **kwargs):\n",
    "        super().__init__((0, 0), (0, 0), *args, **kwargs)\n",
    "        self._xyz = (x, y, z)\n",
    "        self._dxdydz = (dx, dy, dz)\n",
    "\n",
    "    def draw(self, renderer):\n",
    "        x1, y1, z1 = self._xyz\n",
    "        dx, dy, dz = self._dxdydz\n",
    "        x2, y2, z2 = (x1 + dx, y1 + dy, z1 + dz)\n",
    "\n",
    "        xs, ys, zs = proj_transform((x1, x2), (y1, y2), (z1, z2), self.axes.M)\n",
    "        self.set_positions((xs[0], ys[0]), (xs[1], ys[1]))\n",
    "        super().draw(renderer)\n",
    "        \n",
    "def _arrow3D(ax, x, y, z, dx, dy, dz, *args, **kwargs):\n",
    "    '''Add an 3d arrow to an `Axes3D` instance.'''\n",
    "\n",
    "    arrow = Arrow3D(x, y, z, dx, dy, dz, *args, **kwargs)\n",
    "    ax.add_artist(arrow)\n",
    "\n",
    "\n",
    "setattr(Axes3D, 'arrow3D', _arrow3D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Looking for the subhalos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "N     = 40000 # Number of samples.\n",
    "\n",
    "Mmin  = 1e10 # Minimum total mass.\n",
    "Mmax  = 1e13 # Maximum total mass.\n",
    "Mdmin = 1e9 # Minimum dark matter mass in half radius.\n",
    "Mdmax = 1e13 # Maximum dark matter mass in half radius.\n",
    "Mgmin = 1e8 # Minimum gas mass.\n",
    "Mgmax = 1e13 # Maximum gas mass.\n",
    "Msmin = 1e10 # Minimum stellar mass.\n",
    "Msmax = 1e12 # Maximum stellar mass.\n",
    "\n",
    "sim   = 'TNG100-1' # Name of simulation run.\n",
    "z     = 99  # Snapshot number.\n",
    "myBasePath = '../sims.TNG/' + sim +'/output/'\n",
    "\n",
    "mass_min      = (Mmin * h) * 1e-10 # Minimum total mass\n",
    "mass_max      = (Mmax * h) * 1e-10 # Maximum total mass\n",
    "dm_mass_min   = (Mdmin * h) * 1e-10 # Minimum total dm mass\n",
    "dm_mass_max   = (Mdmax * h) * 1e-10 # Maximum total dm mass\n",
    "gas_mass_min  = (Mgmin * h) * 1e-10 # Minimum total gas mass\n",
    "gas_mass_max  = (Mgmax * h) * 1e-10 # Maximum total gas mass\n",
    "star_mass_min = (Msmin * h) * 1e-10 # Minimum total star mass\n",
    "star_mass_max = (Msmax * h) * 1e-10 # Maximum total star mass\n",
    "\n",
    "\n",
    "subhalos_url = 'http://www.tng-project.org/api/' + sim + '/snapshots/' + str(z) + '/subhalos'\n",
    "url          = subhalos_url\n",
    "subhalos     = get(subhalos_url, {'limit': N, 'offset': 0,\n",
    "                                #'mass__gt': mass_min, 'mass__lt': mass_max,                                     \n",
    "                                #'massinhalfrad_dm__gt':dm_mass_min,'massinhalfrad_dm__lt':dm_mass_max, \n",
    "                                #'mass_gas__gt': gas_mass_min, #'mass_gas__lt': gas_mass_max,\n",
    "                                'mass_stars__gt': star_mass_min,# 'mass_stars__lt': star_mass_max,\n",
    "                                'filterFlag': True, 'parent__lt':1, \n",
    "                                'sfr__gt':0.1,\n",
    "                                'subhaloflag__gt':0})\n",
    "\n",
    "nsubhalos = len(subhalos['results'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4071"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nsubhalos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Analyzing each individual subhalo (ie galaxy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/u/m/mdelosri/MaDaMe/codes\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = '../data/gals_properties.h5'\n",
    "data = h5py.File(file, 'a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MainProps', 'SubID_0']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(data.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    flag_MainProps = True\n",
    "    old_MainProps = data['MainProps'][()]\n",
    "except:\n",
    "    flag_MainProps = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<KeysViewHDF5 ['SubID_400547']>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [00:02<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[40], line 36\u001b[0m\n\u001b[1;32m     34\u001b[0m sub_meta \u001b[38;5;241m=\u001b[39m get(subhalos[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresults\u001b[39m\u001b[38;5;124m'\u001b[39m][i][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124murl\u001b[39m\u001b[38;5;124m'\u001b[39m])    \n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m# --------------------------------------------------------\u001b[39;00m\n\u001b[0;32m---> 36\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ids \u001b[38;5;241m==\u001b[39m \u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43msub_meta\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrelated\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mparent_halo\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmeta\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43minfo\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGroupFirstSub\u001b[39m\u001b[38;5;124m'\u001b[39m]: \u001b[38;5;66;03m# Keep only central galaxies\u001b[39;00m\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSubID_\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(ids) \u001b[38;5;129;01min\u001b[39;00m data\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m     38\u001b[0m         flag_gr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;66;03m# This means that we do not have to analyze the group\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[7], line 6\u001b[0m, in \u001b[0;36mget\u001b[0;34m(path, params, folderName)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03mIllustris function\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# make HTTP GET request to path\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43mrequests\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# raise exception if response code is not HTTP SUCCESS (200)\u001b[39;00m\n\u001b[1;32m      9\u001b[0m r\u001b[38;5;241m.\u001b[39mraise_for_status()\n",
      "File \u001b[0;32m~/miniconda3/envs/martini/lib/python3.9/site-packages/requests/api.py:73\u001b[0m, in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(url, params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     63\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \n\u001b[1;32m     65\u001b[0m \u001b[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;124;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 73\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mget\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/martini/lib/python3.9/site-packages/requests/api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sessions\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/martini/lib/python3.9/site-packages/requests/sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[1;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[1;32m    587\u001b[0m }\n\u001b[1;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m~/miniconda3/envs/martini/lib/python3.9/site-packages/requests/sessions.py:724\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    721\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m allow_redirects:\n\u001b[1;32m    722\u001b[0m     \u001b[38;5;66;03m# Redirect resolving generator.\u001b[39;00m\n\u001b[1;32m    723\u001b[0m     gen \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresolve_redirects(r, request, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 724\u001b[0m     history \u001b[38;5;241m=\u001b[39m [resp \u001b[38;5;28;01mfor\u001b[39;00m resp \u001b[38;5;129;01min\u001b[39;00m gen]\n\u001b[1;32m    725\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    726\u001b[0m     history \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m~/miniconda3/envs/martini/lib/python3.9/site-packages/requests/sessions.py:724\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    721\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m allow_redirects:\n\u001b[1;32m    722\u001b[0m     \u001b[38;5;66;03m# Redirect resolving generator.\u001b[39;00m\n\u001b[1;32m    723\u001b[0m     gen \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresolve_redirects(r, request, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 724\u001b[0m     history \u001b[38;5;241m=\u001b[39m [resp \u001b[38;5;28;01mfor\u001b[39;00m resp \u001b[38;5;129;01min\u001b[39;00m gen]\n\u001b[1;32m    725\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    726\u001b[0m     history \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m~/miniconda3/envs/martini/lib/python3.9/site-packages/requests/sessions.py:265\u001b[0m, in \u001b[0;36mSessionRedirectMixin.resolve_redirects\u001b[0;34m(self, resp, req, stream, timeout, verify, cert, proxies, yield_requests, **adapter_kwargs)\u001b[0m\n\u001b[1;32m    263\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m req\n\u001b[1;32m    264\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 265\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    266\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    267\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverify\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverify\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcert\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43madapter_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    276\u001b[0m     extract_cookies_to_jar(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcookies, prepared_request, resp\u001b[38;5;241m.\u001b[39mraw)\n\u001b[1;32m    278\u001b[0m     \u001b[38;5;66;03m# extract redirect url, if any, for the next loop\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/martini/lib/python3.9/site-packages/requests/sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    700\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[1;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43madapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[1;32m    706\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[0;32m~/miniconda3/envs/martini/lib/python3.9/site-packages/requests/adapters.py:667\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    664\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m TimeoutSauce(connect\u001b[38;5;241m=\u001b[39mtimeout, read\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m    666\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 667\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    668\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    669\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    670\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    671\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    672\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    673\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    674\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    675\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    676\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    677\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    678\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    679\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    681\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    682\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request\u001b[38;5;241m=\u001b[39mrequest)\n",
      "File \u001b[0;32m~/miniconda3/envs/martini/lib/python3.9/site-packages/urllib3/connectionpool.py:789\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    786\u001b[0m response_conn \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    788\u001b[0m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[0;32m--> 789\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    790\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    791\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    792\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    793\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    794\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    795\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    796\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    797\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    798\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    799\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    800\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    801\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    802\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    804\u001b[0m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n\u001b[1;32m    805\u001b[0m clean_exit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/martini/lib/python3.9/site-packages/urllib3/connectionpool.py:536\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    534\u001b[0m \u001b[38;5;66;03m# Receive the response from the server\u001b[39;00m\n\u001b[1;32m    535\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 536\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    537\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    538\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_timeout(err\u001b[38;5;241m=\u001b[39me, url\u001b[38;5;241m=\u001b[39murl, timeout_value\u001b[38;5;241m=\u001b[39mread_timeout)\n",
      "File \u001b[0;32m~/miniconda3/envs/martini/lib/python3.9/site-packages/urllib3/connection.py:507\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    504\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mresponse\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HTTPResponse\n\u001b[1;32m    506\u001b[0m \u001b[38;5;66;03m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[0;32m--> 507\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    509\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    510\u001b[0m     assert_header_parsing(httplib_response\u001b[38;5;241m.\u001b[39mmsg)\n",
      "File \u001b[0;32m~/miniconda3/envs/martini/lib/python3.9/http/client.py:1377\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1375\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1376\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1377\u001b[0m         \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1378\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[1;32m   1379\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/miniconda3/envs/martini/lib/python3.9/http/client.py:320\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[1;32m    319\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 320\u001b[0m     version, status, reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    321\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m CONTINUE:\n\u001b[1;32m    322\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/martini/lib/python3.9/http/client.py:281\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    280\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 281\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_MAXLINE\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miso-8859-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    282\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) \u001b[38;5;241m>\u001b[39m _MAXLINE:\n\u001b[1;32m    283\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus line\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/martini/lib/python3.9/socket.py:716\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    714\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    715\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 716\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    717\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    718\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/martini/lib/python3.9/ssl.py:1275\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1271\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1272\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1273\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1274\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m-> 1275\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1276\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1277\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[0;32m~/miniconda3/envs/martini/lib/python3.9/ssl.py:1133\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1132\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1133\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1134\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1135\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#itialization of properties \n",
    "save_part_halo = True\n",
    "save_part_subhalo = True\n",
    "\n",
    "nsubhalos = 50\n",
    "properties = np.zeros((nsubhalos, 17))\n",
    "\n",
    "rmax = 1000 # kPc\n",
    "# 0: ID\n",
    "# 1: central (1 if central, 0 if not)\n",
    "# 2: SubMass [Msun]\n",
    "# 3: SubSFR\n",
    "# 4: SubHMR [kPc]\n",
    "# 5: x [kPc]\n",
    "# 6: y [kPc]\n",
    "# 7: z [kPc]\n",
    "# 8: vx [km/s]\n",
    "# 9: vy [km/s]\n",
    "# 10: vz [km/s]\n",
    "# 11: SubVmax [km/s]\n",
    "# 12: SubVmaxR [kPc]\n",
    "# 13: SubHMRG [kPc] Comoving radius containing half of the mass of this Subhalo \n",
    "                    # split by Type (SubhaloMassType). Type 4 = gas\n",
    "# 14: costheta. Cosine of the angle between the angular momenta and the main axis\n",
    "                # of the inertia tensor.\n",
    "# 15: kappa_AM\n",
    "# 16: kappa_IT\n",
    "\n",
    "#i = 2\n",
    "for i in tqdm(range(nsubhalos)):\n",
    "    print(data.keys())\n",
    "    ids = subhalos['results'][i]['id']\n",
    "    # Let's load the data of the subhalos\n",
    "    sub_meta = get(subhalos['results'][i]['url'])    \n",
    "    # --------------------------------------------------------\n",
    "    if ids == get(get(sub_meta['related']['parent_halo'])['meta']['info'])['GroupFirstSub']: # Keep only central galaxies\n",
    "        if 'SubID_' + str(ids) in data.keys():\n",
    "            flag_gr = False # This means that we do not have to analyze the group\n",
    "            print('Subhalo ' + str(ids) + ' already exists')\n",
    "            if not data['SubID_' + str(ids)].attrs['done']:\n",
    "                print('The analysis of the subhalo was not finished OK, so we have to do it again :(')\n",
    "                flag_gr = True # This means that we have to analyze the group\n",
    "                del data['SubID_' + str(ids)]\n",
    "                gr = data.create_group('SubID_' + str(ids))\n",
    "        else:\n",
    "            gr = data.create_group('SubID_' + str(ids))\n",
    "            flag_gr = True # This means that we have to analyze the group\n",
    "            gr.attrs['done'] = False\n",
    "    \n",
    "        if flag_gr:\n",
    "            # Let's save the main properties  ------------------------           \n",
    "            properties[i, 0] = ids   \n",
    "            gid = sub_meta['grnr'] # sub_meta['SubhaloGrNr']\n",
    "            properties[i, 1] = gid\n",
    "            properties[i, 2] = sub_meta['mass'] * 1e10 / h # [Msun] #sub_meta['SubhaloMass'] * 1e10 / h\n",
    "            properties[i, 3] = sub_meta['sfr'] # [Msun/yr] # sub_meta['SubhaloSFR']\n",
    "            properties[i, 4] = sub_meta['halfmassrad'] / h # [kPc]  # sub_meta['SubhaloHalfmassRad'] / h\n",
    "            properties[i, 5] = sub_meta['pos_x'] / h # [kPc]  # sub_meta['SubhaloPos'][0] / h\n",
    "            properties[i, 6] = sub_meta['pos_y'] / h # [kPc]  # sub_meta['SubhaloPos'][1] / h\n",
    "            properties[i, 7] = sub_meta['pos_z'] / h # [kPc]  # sub_meta['SubhaloPos'][2] / h\n",
    "            properties[i, 8] = sub_meta['vel_x'] # [km/s] # sub_meta['SubhaloVel'][0]\n",
    "            properties[i, 9] = sub_meta['vel_y'] # [km/s] # sub_meta['SubhaloVel'][1]\n",
    "            properties[i, 10] = sub_meta['vel_z'] # [km/s] # sub_meta['SubhaloVel'][2]\n",
    "            properties[i, 11] = sub_meta['vmax'] # [km/s] # sub_meta['SubhaloVmax']\n",
    "            properties[i, 12] = sub_meta['vmaxrad'] / h # [kPc] # sub_meta['SubhaloVmaxRad'] / h\n",
    "            properties[i, 13] = sub_meta['halfmassrad_stars'] / h # [kPc] # sub_meta['SubhaloHalfmassRadType'][4] / h\n",
    "    \n",
    "    \n",
    "            gr.create_dataset('Props', data = properties[i,:])\n",
    "            # --------------------------------------------------------\n",
    "    \n",
    "            # Let's estimate properties with the particles of the subhalos\n",
    "            print('Starting the estimation of properties with subhalo particles for galaxy ' + str(ids))\n",
    "            sub_data_url = subhalos['results'][i]['url'] + 'vis.hdf5'\n",
    "            center_sub   = properties[i, 5:8]\n",
    "            velocity     = properties[i, 8:11]\n",
    "    \n",
    "            \n",
    "            stars_subhalo = get(subhalos['results'][i]['url'] + '/' + 'cutout.hdf5', \n",
    "                               {'stars':'Coordinates,GFM_InitialMass,GFM_Metallicity,GFM_StellarFormationTime,Masses,StellarHsml,Velocities'})\n",
    "            stars_c = stars_subhalo[0] / h\n",
    "            stars_v = stars_subhalo[6]\n",
    "            stars_m = stars_subhalo[4] * 1e10 / h\n",
    "            try:\n",
    "                gas_subhalo = get(subhalos['results'][i]['url'] + '/' + 'cutout.hdf5', \n",
    "                       {'gas':'coordinates,density,ElectronAbundance,GFM_Metallicity,GFM_Metals,InternalEnergy,masses,SubfindHsml,velocities'})\n",
    "    \n",
    "                #gas_subhalo = get(subhalos['results'][i]['url'] + '/' + 'cutout.hdf5', \n",
    "                #                   {'gas':'coordinates,density,GFM_Metallicity,masses,SubfindHsml,velocities'})\n",
    "                gas_c   = gas_subhalo[0] / h\n",
    "                gas_v   = gas_subhalo[8]\n",
    "                gas_m   = gas_subhalo[6] * 1e10 / h\n",
    "                gas_HI  = gas_subhalo[4][:,0]\n",
    "                flag_gas = True\n",
    "            except:\n",
    "                print('Galaxy ' + str(ids) + ' have no gas')\n",
    "                flag_gas = False\n",
    "            dm_c    = get(subhalos['results'][i]['url'] + 'cutout.hdf5', {'dm':'Coordinates'})[0] / h\n",
    "            dm_v    = get(subhalos['results'][i]['url'] + 'cutout.hdf5', {'dm':'Velocities'})[0]\n",
    "    \n",
    "            # Let's move the coordinates if they are near the border\n",
    "            aux_ind = np.where( (stars_c[:, 0] - center_sub[0]) > (box_size / 2) )[0]\n",
    "            stars_c[aux_ind, 0] = stars_c[aux_ind, 0] - box_size\n",
    "            aux_ind = np.where( (center_sub[0] - stars_c[:, 0]) > (box_size / 2) )[0]\n",
    "            stars_c[aux_ind, 0] = stars_c[aux_ind, 0] + box_size\n",
    "            aux_ind = np.where( (stars_c[:, 1] - center_sub[1]) > (box_size / 2) )[0]\n",
    "            stars_c[aux_ind, 1] = stars_c[aux_ind, 1] - box_size\n",
    "            aux_ind = np.where( (center_sub[1] - stars_c[:, 1]) > (box_size / 2) )[0]\n",
    "            stars_c[aux_ind, 1] = stars_c[aux_ind, 1] + box_size\n",
    "            aux_ind = np.where( (stars_c[:, 2] - center_sub[2]) > (box_size / 2) )[0]\n",
    "            stars_c[aux_ind, 2] = stars_c[aux_ind, 2] - box_size\n",
    "            aux_ind = np.where( (center_sub[2] - stars_c[:, 2]) > (box_size / 2) )[0]\n",
    "            stars_c[aux_ind, 2] = stars_c[aux_ind, 2] + box_size\n",
    "            \n",
    "            if flag_gas:\n",
    "                aux_ind = np.where( (gas_c[:, 0] - center_sub[0]) > (box_size / 2) )[0]\n",
    "                gas_c[aux_ind, 0] = gas_c[aux_ind, 0] - box_size\n",
    "                aux_ind = np.where( (center_sub[0] - gas_c[:, 0]) > (box_size / 2) )[0]\n",
    "                gas_c[aux_ind, 0] = gas_c[aux_ind, 0] + box_size\n",
    "                aux_ind = np.where( (gas_c[:, 1] - center_sub[1]) > (box_size / 2) )[0]\n",
    "                gas_c[aux_ind, 1] = gas_c[aux_ind, 1] - box_size\n",
    "                aux_ind = np.where( (center_sub[1] - gas_c[:, 1]) > (box_size / 2) )[0]\n",
    "                gas_c[aux_ind, 1] = gas_c[aux_ind, 1] + box_size\n",
    "                aux_ind = np.where( (gas_c[:, 2] - center_sub[2]) > (box_size / 2) )[0]\n",
    "                gas_c[aux_ind, 2] = gas_c[aux_ind, 2] - box_size\n",
    "                aux_ind = np.where( (center_sub[2] - gas_c[:, 2]) > (box_size / 2) )[0]\n",
    "                gas_c[aux_ind, 2] = gas_c[aux_ind, 2] + box_size\n",
    "                \n",
    "            aux_ind = np.where( (dm_c[:, 0] - center_sub[0]) > (box_size / 2) )[0]\n",
    "            dm_c[aux_ind, 0] = dm_c[aux_ind, 0] - box_size\n",
    "            aux_ind = np.where( (center_sub[0] - dm_c[:, 0]) > (box_size / 2) )[0]\n",
    "            dm_c[aux_ind, 0] = dm_c[aux_ind, 0] + box_size\n",
    "            aux_ind = np.where( (dm_c[:, 1] - center_sub[1]) > (box_size / 2) )[0]\n",
    "            dm_c[aux_ind, 1] = dm_c[aux_ind, 1] - box_size\n",
    "            aux_ind = np.where( (center_sub[1] - dm_c[:, 1]) > (box_size / 2) )[0]\n",
    "            dm_c[aux_ind, 1] = dm_c[aux_ind, 1] + box_size\n",
    "            aux_ind = np.where( (dm_c[:, 2] - center_sub[2]) > (box_size / 2) )[0]\n",
    "            dm_c[aux_ind, 2] = dm_c[aux_ind, 2] - box_size\n",
    "            aux_ind = np.where( (center_sub[2] - dm_c[:, 2]) > (box_size / 2) )[0]\n",
    "            dm_c[aux_ind, 2] = dm_c[aux_ind, 2] + box_size\n",
    "            # --------------------------------------------------------\n",
    "            \n",
    "            # ------------------Let's center the particles -----------\n",
    "            stars_c = stars_c - center_sub\n",
    "            stars_v = stars_v - velocity\n",
    "            \n",
    "            dm_v = dm_v - velocity\n",
    "            dm_c = dm_c - center_sub\n",
    "            \n",
    "            if flag_gas:\n",
    "                gas_c = gas_c - center_sub\n",
    "                gas_v = gas_v - velocity\n",
    "            # --------------------------------------------------------\n",
    "                  \n",
    "            # Let's Compute the distance of each DM particle to the center and sum in radial bins\n",
    "            dist = np.linalg.norm(dm_c, axis=1)\n",
    "            #for d in dm_c:\n",
    "            #    D = np.sqrt(sum([c**2 for c in d]))\n",
    "            #    if D < 100: dist.append(D)\n",
    "            M = np.array([len(np.where(np.array(dist) < R)[0]) * M_dm for R in R_bins])\n",
    "            if rmax == None: rmax = (3 * properties[i, 4]) # max radii for saving particles\n",
    "            ind_dm = np.where(np.array(dist) < rmax)[0] # for saving only close particles\n",
    "            # --------------------------------------------------------\n",
    "    \n",
    "            # Let's Compute the distance of each star particle to the center and sum in radial bins\n",
    "            dist = np.linalg.norm(stars_c, axis=1)\n",
    "            #for d in stars_c:\n",
    "            #    D = np.sqrt(sum([c**2 for c in d]))\n",
    "            #    if D < 100: dist.append(D)\n",
    "            M_stars = np.array([np.sum( stars_m[np.where(np.array(dist) < R)[0]] ) for R in R_bins])\n",
    "            ind_stars = np.where(np.array(dist) < rmax)[0] # for saving only close particles\n",
    "            # --------------------------------------------------------\n",
    "    \n",
    "            # Compute the distance of each particle to the center and sum in radial bins\n",
    "            if flag_gas:\n",
    "                dist = np.linalg.norm(gas_c, axis=1)\n",
    "                #for d in gas_c:\n",
    "                #    D = np.sqrt(sum([c**2 for c in d]))\n",
    "                #    if D < 100: dist.append(D)\n",
    "                M_gas = np.array([np.sum( gas_m[np.where(np.array(dist) < R)[0]] ) for R in R_bins])\n",
    "                ind_gas = np.where(np.array(dist) < rmax)[0] # for saving only close particles\n",
    "            # --------------------------------------------------------\n",
    "    \n",
    "            # Let's save the particles\n",
    "            if save_part_subhalo:\n",
    "                np.savetxt('../data/particles/subhalo_' + str(ids) + '_starsCoord.txt', stars_c[ind_stars])\n",
    "                #np.savetxt('../data/particles/subhalo_' + str(ids) + '_starsCoord.txt', aux_subhalo[0])\n",
    "                np.savetxt('../data/particles/subhalo_' + str(ids) + '_starsInitMass.txt', stars_subhalo[1][ind_stars])\n",
    "                np.savetxt('../data/particles/subhalo_' + str(ids) + '_starsMetal.txt', stars_subhalo[2][ind_stars])\n",
    "                np.savetxt('../data/particles/subhalo_' + str(ids) + '_starsSFT.txt', stars_subhalo[3][ind_stars])\n",
    "                np.savetxt('../data/particles/subhalo_' + str(ids) + '_starsMasses.txt', stars_m[ind_stars])\n",
    "                np.savetxt('../data/particles/subhalo_' + str(ids) + '_starsHsml.txt', stars_subhalo[5][ind_stars])\n",
    "                np.savetxt('../data/particles/subhalo_' + str(ids) + '_starsVels.txt', stars_v[ind_stars])\n",
    "                if flag_gas:\n",
    "                    np.savetxt('../data/particles/subhalo_' + str(ids) + '_gasCoord.txt', gas_c[ind_gas])\n",
    "                    np.savetxt('../data/particles/subhalo_' + str(ids) + '_gasDens.txt', gas_subhalo[1][ind_gas])\n",
    "                    np.savetxt('../data/particles/subhalo_' + str(ids) + '_eAbund.txt', gas_subhalo[2][ind_gas])\n",
    "                    np.savetxt('../data/particles/subhalo_' + str(ids) + '_gasMetal.txt', gas_subhalo[3][ind_gas])\n",
    "                    np.savetxt('../data/particles/subhalo_' + str(ids) + '_gasHI.txt', gas_HI[ind_gas])\n",
    "                    np.savetxt('../data/particles/subhalo_' + str(ids) + '_intEne.txt', gas_subhalo[5][ind_gas])\n",
    "                    np.savetxt('../data/particles/subhalo_' + str(ids) + '_gasMasses.txt', gas_m[ind_gas])\n",
    "                    np.savetxt('../data/particles/subhalo_' + str(ids) + '_gasHsml.txt', gas_subhalo[7][ind_gas])\n",
    "                    np.savetxt('../data/particles/subhalo_' + str(ids) + '_gasVels.txt', gas_v[ind_gas])\n",
    "            # ----------------------------------------------\n",
    "            \n",
    "            # Let's save the data of these profiles\n",
    "            gr.create_dataset('R_bins_sub', data = R_bins)\n",
    "            gr.create_dataset('M_DM_sub', data = M)\n",
    "            gr.create_dataset('M_stars_sub', data = M_stars)   \n",
    "            if flag_gas:\n",
    "                gr.create_dataset('M_gas_sub', data = M_gas)\n",
    "            # --------------------------------------------------------\n",
    "    \n",
    "            # Let's compute the rotation matrix taking into accunt the inertia tensor\n",
    "            rot_mat_IT, L_IT = compute_rot_mat_inertia(np.zeros(3), stars_c, stars_m, Rmax = 2 * properties[i, 13])\n",
    "            # --------------------------------------------------------\n",
    "    \n",
    "            # Let's compute the rotation matrix taking into accunt the angular momentum tensor\n",
    "            rot_mat_AM, L_AM = compute_rot_mat_angMom(np.zeros(3), stars_c, stars_v, stars_m, Rmax = 2 * properties[i, 13])\n",
    "            # --------------------------------------------------------\n",
    "    \n",
    "            # Let's rotate the coordiantes with AM\n",
    "            dm_c_rot_AM = dm_c @ rot_mat_AM\n",
    "            dm_v_rot_AM = dm_v @ rot_mat_AM\n",
    "            stars_c_rot_AM = stars_c @ rot_mat_AM\n",
    "            stars_v_rot_AM = stars_v @ rot_mat_AM\n",
    "            if flag_gas:\n",
    "                gas_c_rot_AM = gas_c @ rot_mat_AM\n",
    "                gas_v_rot_AM = gas_v @ rot_mat_AM\n",
    "    \n",
    "            L_AM_rot_AM = L_AM @ rot_mat_AM\n",
    "            L_IT_rot_AM = L_IT @ rot_mat_AM\n",
    "            # --------------------------------------------------------\n",
    "    \n",
    "            # Let's rotate the coordiantes with IT\n",
    "            dm_c_rot_IT = dm_c @ rot_mat_IT\n",
    "            dm_v_rotv = dm_v @ rot_mat_IT\n",
    "            stars_c_rot_IT = stars_c @ rot_mat_IT\n",
    "            stars_v_rot_IT = stars_v @ rot_mat_IT\n",
    "            if flag_gas:\n",
    "                gas_c_rot_IT = gas_c @ rot_mat_IT\n",
    "                gas_v_rot_IT = gas_v @ rot_mat_IT\n",
    "    \n",
    "            L_AM_rot_IT = L_AM @ rot_mat_IT\n",
    "            L_IT_rot_IT = L_IT @ rot_mat_IT\n",
    "            # --------------------------------------------------------\n",
    "    \n",
    "            # Let's aligendthe stars with the IT\n",
    "            x_stars_IT  = stars_c_rot_IT[:,0]\n",
    "            y_stars_IT  = stars_c_rot_IT[:,1]\n",
    "            z_stars_IT  = stars_c_rot_IT[:,2]\n",
    "            vx_stars_IT = stars_v_rot_IT[:,0]\n",
    "            vy_stars_IT = stars_v_rot_IT[:,1]\n",
    "            vz_stars_IT = stars_v_rot_IT[:,2]\n",
    "            # --------------------------------------------------------\n",
    "    \n",
    "    \n",
    "            # Let's move to cylindrical coordinates and the kinematical properties\n",
    "            r_stars_IT         = np.sqrt(x_stars_IT**2 + y_stars_IT**2)\n",
    "            phi_stars_IT       = np.arctan2(y_stars_IT, x_stars_IT)\n",
    "            jz_stars_IT        = x_stars_IT * vy_stars_IT - y_stars_IT * vx_stars_IT\n",
    "            Erot_stars_IT      = stars_m * (jz_stars_IT**2) / (r_stars_IT**2)\n",
    "            Ek_stars_IT        = stars_m * (vx_stars_IT**2 + vy_stars_IT**2 + vz_stars_IT**2)\n",
    "            kappa_stars_IT     = np.sum(Erot_stars_IT) / np.sum(Ek_stars_IT)\n",
    "            vphi_full_stars_IT = jz_stars_IT / r_stars_IT\n",
    "            # --------------------------------------------------------\n",
    "    \n",
    "    \n",
    "            # Now aligend the stars with the AM\n",
    "    \n",
    "            x_stars_AM  = stars_c_rot_AM[:,0]\n",
    "            y_stars_AM  = stars_c_rot_AM[:,1]\n",
    "            z_stars_AM  = stars_c_rot_AM[:,2]\n",
    "            vx_stars_AM = stars_v_rot_AM[:,0]\n",
    "            vy_stars_AM = stars_v_rot_AM[:,1]\n",
    "            vz_stars_AM = stars_v_rot_AM[:,2]\n",
    "            # --------------------------------------------------------\n",
    "    \n",
    "            # Let's move to cylindrical coordinates and the kinematical properties\n",
    "            r_stars_AM     = np.sqrt(x_stars_AM**2 + y_stars_AM**2)\n",
    "            phi_stars_AM   = np.arctan2(y_stars_AM, x_stars_AM)\n",
    "            jz_stars_AM    = x_stars_AM * vy_stars_AM - y_stars_AM * vx_stars_AM\n",
    "            Erot_stars_AM  = stars_m * (jz_stars_AM**2) / (r_stars_AM**2)\n",
    "            Ek_stars_AM    = stars_m * (vx_stars_AM**2 + vy_stars_AM**2 + vz_stars_AM**2)\n",
    "            kappa_stars_AM = np.sum(Erot_stars_AM) / np.sum(Ek_stars_AM)\n",
    "            vphi_full_stars_AM = jz_stars_AM / r_stars_AM\n",
    "            # --------------------------------------------------------\n",
    "    \n",
    "            # Let's save the main properties\n",
    "            properties[i, 14] = np.dot(L_IT, L_AM) / ( np.linalg.norm(L_IT) * np.linalg.norm(L_AM) )\n",
    "            properties[i, 15] = kappa_stars_AM\n",
    "            properties[i, 16] = kappa_stars_IT\n",
    "            # --------------------------------------------------------\n",
    "    \n",
    "            # Let's compute rotation curve with gas\n",
    "    \n",
    "            # Let's aligend the gas with the IT\n",
    "            if flag_gas:\n",
    "                x_gas_IT  = gas_c_rot_IT[:,0]\n",
    "                y_gas_IT  = gas_c_rot_IT[:,1]\n",
    "                z_gas_IT  = gas_c_rot_IT[:,2]\n",
    "                vx_gas_IT = gas_v_rot_IT[:,0]\n",
    "                vy_gas_IT = gas_v_rot_IT[:,1]\n",
    "                vz_gas_IT = gas_v_rot_IT[:,2]\n",
    "                # --------------------------------------------------------\n",
    "    \n",
    "                # Let's move to cylindrical coordinates and compute the kinematical properties\n",
    "                r_gas_IT         = np.sqrt(x_gas_IT**2 + y_gas_IT**2)\n",
    "                phi_gas_IT       = np.arctan2(y_gas_IT, x_gas_IT)\n",
    "                jz_gas_IT        = x_gas_IT * vy_gas_IT - y_gas_IT * vx_gas_IT\n",
    "                Erot_gas_IT      = gas_m * (jz_gas_IT**2) / (r_gas_IT**2)\n",
    "                Ek_gas_IT        = gas_m * (vx_gas_IT**2 + vy_gas_IT**2 + vz_gas_IT**2)\n",
    "                kappa_gas_IT     = np.sum(Erot_gas_IT) / np.sum(Ek_gas_IT)\n",
    "                vphi_full_gas_IT = jz_gas_IT / r_gas_IT\n",
    "                # --------------------------------------------------------\n",
    "    \n",
    "                # Now let's aligend the gas with the AM\n",
    "    \n",
    "                x_gas_AM  = gas_c_rot_AM[:,0]\n",
    "                y_gas_AM  = gas_c_rot_AM[:,1]\n",
    "                z_gas_AM  = gas_c_rot_AM[:,2]\n",
    "                vx_gas_AM = gas_v_rot_AM[:,0]\n",
    "                vy_gas_AM = gas_v_rot_AM[:,1]\n",
    "                vz_gas_AM = gas_v_rot_AM[:,2]\n",
    "    \n",
    "                # Let's move to cylindrical coordinates and compute the kinematical properties\n",
    "                r_gas_AM     = np.sqrt(x_gas_AM**2 + y_gas_AM**2)\n",
    "                phi_gas_AM   = np.arctan2(y_gas_AM, x_gas_AM)\n",
    "                jz_gas_AM    = x_gas_AM * vy_gas_AM - y_gas_AM * vx_gas_AM\n",
    "                Erot_gas_AM  = gas_m * (jz_gas_AM**2) / (r_gas_AM**2)\n",
    "                Ek_gas_AM    = gas_m * (vx_gas_AM**2 + vy_gas_AM**2 + vz_gas_AM**2)\n",
    "                kappa_gas_AM = np.sum(Erot_gas_AM) / np.sum(Ek_gas_AM)\n",
    "                vphi_full_gas_AM = jz_gas_AM / r_gas_AM\n",
    "                # --------------------------------------------------------\n",
    "    \n",
    "                # Let's compute the binned rotational curves and saved it\n",
    "                v_rot_gas_IT, bin_edges,_ = binned_statistic(r_gas_IT, np.abs(vphi_full_gas_IT), 'mean', bins = R_bins)\n",
    "                v_std_gas_IT,_,_ = binned_statistic(r_gas_IT, np.abs(vphi_full_gas_IT), 'std', bins = R_bins)\n",
    "                v_rot_gas_AM,_,_ = binned_statistic(r_gas_AM, np.abs(vphi_full_gas_AM), 'mean', bins = R_bins)\n",
    "                v_std_gas_AM,_,_ = binned_statistic(r_gas_AM, np.abs(vphi_full_gas_IT), 'std', bins = R_bins)\n",
    "    \n",
    "            v_rot_stars_IT, bin_edges,_  = binned_statistic(r_stars_IT, np.abs(vphi_full_stars_IT), 'mean', bins = R_bins)\n",
    "            v_std_stars_IT,_,_ = binned_statistic(r_stars_IT, np.abs(vphi_full_stars_IT), 'std', bins = R_bins)\n",
    "            v_rot_stars_AM,_,_ = binned_statistic(r_stars_AM, np.abs(vphi_full_stars_AM), 'mean', bins = R_bins)\n",
    "            v_std_stars_AM,_,_ = binned_statistic(r_stars_AM, np.abs(vphi_full_stars_AM), 'std', bins = R_bins)\n",
    "    \n",
    "            bin_width = (bin_edges[1] - bin_edges[0])\n",
    "            bin_centers = bin_edges[1:] - bin_width/2\n",
    "    \n",
    "            gr.create_dataset('R_bins_vels', data = bin_centers)\n",
    "            if flag_gas:\n",
    "                gr.create_dataset('V_rot_gas_IT', data = v_rot_gas_IT)\n",
    "                gr.create_dataset('V_std_gas_IT', data = v_std_gas_IT)\n",
    "                gr.create_dataset('V_rot_gas_AM', data = v_rot_gas_AM)\n",
    "                gr.create_dataset('V_std_gas_AM', data = v_std_gas_AM)\n",
    "            gr.create_dataset('V_rot_stars_IT', data = v_rot_stars_IT)\n",
    "            gr.create_dataset('V_std_stars_IT', data = v_std_stars_IT)\n",
    "            gr.create_dataset('V_rot_stars_AM', data = v_rot_stars_AM)\n",
    "            gr.create_dataset('V_std_stars_AM', data = v_std_stars_AM)\n",
    "            # ---------------------------------------------------------------------------------------\n",
    "    \n",
    "            # Let's estimate the real profiles taking into account the halo\n",
    "            print('Starting the estimation of properties with halo particles for galaxy ' + str(ids))\n",
    "    \n",
    "            # Let's load the DM particles of the halo to which the subhalo belongs\n",
    "            #dm_halo = il.snapshot.loadHalo('/home/tnguser/sims.TNG/TNG100-1/output/', 99, gid, 'dm', fields=['Coordinates']) / h\n",
    "            dm_halo = get('http://www.tng-project.org/api/TNG100-1/snapshots/99/halos/' + str(gid) + '/' + 'cutout.hdf5', {'dm':'coordinates'})[0] / h\n",
    "            \n",
    "            # ---------------------------------------------------------------------------------------\n",
    "    \n",
    "            # If the halo is near the border let's center it\n",
    "            aux_ind = np.where( (dm_halo[:, 0] - center_sub[0]) > (box_size / 2) )[0]\n",
    "            dm_halo[aux_ind, 0] = dm_halo[aux_ind, 0] - box_size\n",
    "            aux_ind = np.where( (center_sub[0] - dm_halo[:, 0]) > (box_size / 2) )[0]\n",
    "            dm_halo[aux_ind, 0] = dm_halo[aux_ind, 0] + box_size\n",
    "            aux_ind = np.where( (dm_halo[:, 1] - center_sub[1]) > (box_size / 2) )[0]\n",
    "            dm_halo[aux_ind, 1] = dm_halo[aux_ind, 1] - box_size\n",
    "            aux_ind = np.where( (center_sub[1] - dm_halo[:, 1]) > (box_size / 2) )[0]\n",
    "            dm_halo[aux_ind, 1] = dm_halo[aux_ind, 1] + box_size\n",
    "            aux_ind = np.where( (dm_halo[:, 2] - center_sub[2]) > (box_size / 2) )[0]\n",
    "            dm_halo[aux_ind, 2] = dm_halo[aux_ind, 2] - box_size\n",
    "            aux_ind = np.where( (center_sub[2] - dm_halo[:, 2]) > (box_size / 2) )[0]\n",
    "            dm_halo[aux_ind, 2] = dm_halo[aux_ind, 2] + box_size\n",
    "            # ---------------------------------------------------------------------------------------\n",
    "            # ----------------------Let's center de coords---------------------\n",
    "            dm_halo = dm_halo - center_sub\n",
    "            # -----------------------------------------------------------------\n",
    "            # Compute the distance of each particle to the center and sum in radial bins\n",
    "            dist = np.linalg.norm(dm_halo, axis=1)\n",
    "            #for d in dm_halo:\n",
    "            #    D = np.sqrt(sum([c**2 for c in d]))\n",
    "            #    if D < 100: dist.append(D)\n",
    "            M = np.array([len(np.where(np.array(dist) < R)[0]) * M_dm for R in R_bins])\n",
    "            # ---------------------------------------------------------------------------------------\n",
    "    \n",
    "            # Let's load the stars particles of the halo to which the subhalo belongs\n",
    "            \n",
    "            stars_halo = get('http://www.tng-project.org/api/TNG100-1/snapshots/99/halos/' + str(gid) + '/' + 'cutout.hdf5', \n",
    "                               {'stars':'Coordinates,GFM_InitialMass,GFM_Metallicity,GFM_StellarFormationTime,Masses,StellarHsml,Velocities'})\n",
    "            #stars_halo = il.snapshot.loadHalo('/home/tnguser/sims.TNG/TNG100-1/output/', 99, gid, 'stars', fields=['Coordinates']) / h\n",
    "            #masses = il.snapshot.loadHalo('/home/tnguser/sims.TNG/TNG100-1/output/', 99, gid, 'stars', fields=['Masses']) * 1e10 / h\n",
    "            stars_halo_c = stars_halo[0] / h\n",
    "            stars_halo_m = stars_halo[4] * 1e10 / h\n",
    "            stars_halo_v = stars_halo[6]\n",
    "    \n",
    "            # ---------------------------------------------------------------------------------------\n",
    "    \n",
    "            # If the halo is near the border let's center it\n",
    "            aux_ind = np.where( (stars_halo_c[:, 0] - center_sub[0]) > (box_size / 2) )[0]\n",
    "            stars_halo_c[aux_ind, 0] = stars_halo_c[aux_ind, 0] - box_size\n",
    "            aux_ind = np.where( (center_sub[0] - stars_halo_c[:, 0]) > (box_size / 2) )[0]\n",
    "            stars_halo_c[aux_ind, 0] = stars_halo_c[aux_ind, 0] + box_size\n",
    "            aux_ind = np.where( (stars_halo_c[:, 1] - center_sub[1]) > (box_size / 2) )[0]\n",
    "            stars_halo_c[aux_ind, 1] = stars_halo_c[aux_ind, 1] - box_size\n",
    "            aux_ind = np.where( (center_sub[1] - stars_halo_c[:, 1]) > (box_size / 2) )[0]\n",
    "            stars_halo_c[aux_ind, 1] = stars_halo_c[aux_ind, 1] + box_size\n",
    "            aux_ind = np.where( (stars_halo_c[:, 2] - center_sub[2]) > (box_size / 2) )[0]\n",
    "            stars_halo_c[aux_ind, 2] = stars_halo_c[aux_ind, 2] - box_size\n",
    "            aux_ind = np.where( (center_sub[2] - stars_halo_c[:, 2]) > (box_size / 2) )[0]\n",
    "            stars_halo_c[aux_ind, 2] = stars_halo_c[aux_ind, 2] + box_size\n",
    "            \n",
    "            # ----------------------Let's center de coords---------------------\n",
    "            stars_halo_c = stars_halo_c - center_sub\n",
    "            stars_halo_v = stars_halo_v - velocity\n",
    "            # ---------------------------------------------------------------------------------------\n",
    "    \n",
    "            # Compute the distance of each particle to the center and sum in radial bins\n",
    "            dist = np.linalg.norm(stars_halo_c, axis=1)\n",
    "            #for d in stars_halo_c:\n",
    "            #    D = np.sqrt(sum([c**2 for c in d]))\n",
    "            #    if D < 100: dist.append(D)\n",
    "            M_stars = np.array([np.sum( stars_halo_m[np.where(np.array(dist) < R)[0]] ) for R in R_bins])\n",
    "            ind_stars = np.where(np.array(dist) < rmax)[0] # Keep only close particles\n",
    "            # ---------------------------------------------------------------------------------------\n",
    "    \n",
    "            # Let's load the stars particles of the halo to which the subhalo belongs\n",
    "            \n",
    "            gas_halo = get('http://www.tng-project.org/api/TNG100-1/snapshots/99/halos/' + str(gid) + '/' + 'cutout.hdf5', \n",
    "                           {'gas':'coordinates,density,ElectronAbundance,GFM_Metallicity,GFM_Metals,InternalEnergy,masses,SubfindHsml,velocities'})        \n",
    "                           #{'gas':'coordinates,density,GFM_Metallicity,masses,SubfindHsml,velocities'})\n",
    "            #gas_halo = il.snapshot.loadHalo('/home/tnguser/sims.TNG/TNG100-1/output/', 99, gid, 'gas', fields=['Coordinates']) / h\n",
    "            #masses = il.snapshot.loadHalo('/home/tnguser/sims.TNG/TNG100-1/output/', 99, gid, 'gas', fields=['Masses']) * 1e10 / h\n",
    "            gas_halo_c = gas_halo[0] / h\n",
    "            gas_halo_m = gas_halo[6] * 1e10 / h\n",
    "            gas_halo_v = gas_halo[8]\n",
    "            gas_halo_HI = gas_halo[4][:,0]\n",
    "    \n",
    "            # ---------------------------------------------------------------------------------------\n",
    "    \n",
    "            # If the halo is near the border let's center it\n",
    "            aux_ind = np.where( (gas_halo_c[:, 0] - center_sub[0]) > (box_size / 2) )[0]\n",
    "            gas_halo_c[aux_ind, 0] = gas_halo_c[aux_ind, 0] - box_size\n",
    "            aux_ind = np.where( (center_sub[0] - gas_halo_c[:, 0]) > (box_size / 2) )[0]\n",
    "            gas_halo_c[aux_ind, 0] = gas_halo_c[aux_ind, 0] + box_size\n",
    "            aux_ind = np.where( (gas_halo_c[:, 1] - center_sub[1]) > (box_size / 2) )[0]\n",
    "            gas_halo_c[aux_ind, 1] = gas_halo_c[aux_ind, 1] - box_size\n",
    "            aux_ind = np.where( (center_sub[1] - gas_halo_c[:, 1]) > (box_size / 2) )[0]\n",
    "            gas_halo_c[aux_ind, 1] = gas_halo_c[aux_ind, 1] + box_size\n",
    "            aux_ind = np.where( (gas_halo_c[:, 2] - center_sub[2]) > (box_size / 2) )[0]\n",
    "            gas_halo_c[aux_ind, 2] = gas_halo_c[aux_ind, 2] - box_size\n",
    "            aux_ind = np.where( (center_sub[2] - gas_halo_c[:, 2]) > (box_size / 2) )[0]\n",
    "            gas_halo_c[aux_ind, 2] = gas_halo_c[aux_ind, 2] + box_size\n",
    "            # ----------------------Let's center de coords---------------------\n",
    "            gas_halo_c = gas_halo_c - center_sub        \n",
    "            gas_halo_v = gas_halo_v - velocity\n",
    "            # ---------------------------------------------------------------------------------------\n",
    "    \n",
    "            # Compute the distance of each particle to the center and sum in radial bins\n",
    "            dist = np.linalg.norm(gas_halo_c, axis=1)\n",
    "            #for d in gas_halo_c:\n",
    "            #    D = np.sqrt(sum([c**2 for c in d]))\n",
    "            #    if D < 100: dist.append(D)\n",
    "            M_gas = np.array([np.sum( gas_halo_m[np.where(np.array(dist) < R)[0]] ) for R in R_bins])\n",
    "    \n",
    "            ind_gas = np.where(np.array(dist) < rmax)[0] # Keep only close particles\n",
    "            gr.create_dataset('R_bins', data = R_bins)\n",
    "            gr.create_dataset('M_DM', data = M)\n",
    "            gr.create_dataset('M_stars', data = M_stars)   \n",
    "            gr.create_dataset('M_gas', data = M_gas)\n",
    "    # ---------------------------------------------------------------------------------------\n",
    "    #except:\n",
    "    #    pass\n",
    "            if save_part_halo:\n",
    "                np.savetxt('../data/particles/halo_' + str(gid) + '_subhalo_' + str(ids) + '_starsCoord.txt', stars_halo_c[ind_stars])\n",
    "                np.savetxt('../data/particles/halo_' + str(gid) + '_subhalo_' + str(ids) + '_starsInitMass.txt', stars_halo[1][ind_stars])\n",
    "                np.savetxt('../data/particles/halo_' + str(gid) + '_subhalo_' + str(ids) + '_starsMetal.txt', stars_halo[2][ind_stars])\n",
    "                np.savetxt('../data/particles/halo_' + str(gid) + '_subhalo_' + str(ids) + '_starsSFT.txt', stars_halo[3][ind_stars])\n",
    "                np.savetxt('../data/particles/halo_' + str(gid) + '_subhalo_' + str(ids) + '_starsMasses.txt', stars_halo_m[ind_stars])\n",
    "                np.savetxt('../data/particles/halo_' + str(gid) + '_subhalo_' + str(ids) + '_starsHsml.txt', stars_halo[5][ind_stars])\n",
    "                np.savetxt('../data/particles/halo_' + str(gid) + '_subhalo_' + str(ids) + '_starsVels.txt', stars_halo_v[ind_stars])\n",
    "                if flag_gas:\n",
    "                    np.savetxt('../data/particles/halo_' + str(gid) + '_subhalo_' + str(ids) + '_gasCoord.txt', gas_halo_c[ind_gas])\n",
    "                    np.savetxt('../data/particles/halo_' + str(gid) + '_subhalo_' + str(ids) + '_gasDens.txt', gas_halo[1][ind_gas])\n",
    "                    np.savetxt('../data/particles/halo_' + str(gid) + '_subhalo_' + str(ids) + '_eAbund.txt', gas_halo[2][ind_gas])\n",
    "                    np.savetxt('../data/particles/halo_' + str(gid) + '_subhalo_' + str(ids) + '_gasMetal.txt', gas_halo[3][ind_gas])\n",
    "                    np.savetxt('../data/particles/halo_' + str(gid) + '_subhalo_' + str(ids) + '_gasHI.txt', gas_halo_HI[ind_gas])\n",
    "                    np.savetxt('../data/particles/halo_' + str(gid) + '_subhalo_' + str(ids) + '_intEne.txt', gas_halo[5][ind_gas])\n",
    "                    np.savetxt('../data/particles/halo_' + str(gid) + '_subhalo_' + str(ids) + '_gasMasses.txt', gas_halo_m[ind_gas])\n",
    "                    np.savetxt('../data/particles/halo_' + str(gid) + '_subhalo_' + str(ids) + '_gasHsml.txt', gas_halo[7][ind_gas])\n",
    "                    np.savetxt('../data/particles/halo_' + str(gid) + '_subhalo_' + str(ids) + '_gasVels.txt', gas_halo_v[ind_gas])\n",
    "    \n",
    "            # Let's save a flag indicating that everything was done\n",
    "            gr.attrs['done'] = True\n",
    "        \n",
    "    # Let's delete from the properties dataset the rows with no info\n",
    "            if (i % 10) == 0:\n",
    "                # After 10 subhalos let's save the data and start again\n",
    "                properties = np.delete(properties, np.where(properties[:,2] == 0)[0], axis = 0)\n",
    "    \n",
    "                if len(properties[:,0] > 0):\n",
    "                    if flag_MainProps:\n",
    "                        properties = np.vstack((old_MainProps, properties))\n",
    "                        del data['MainProps']\n",
    "                        data.create_dataset('MainProps', data = properties)\n",
    "                    else:\n",
    "                        data.create_dataset('MainProps', data = properties)\n",
    "                data.close()\n",
    "                data = h5py.File(file, 'a')\n",
    "                try:\n",
    "                    flag_MainProps = True\n",
    "                    old_MainProps = data['MainProps'][()]\n",
    "                except:\n",
    "                    flag_MainProps = False\n",
    "                properties = np.zeros((nsubhalos, 17))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Full pipe-line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_folder = '../data/tmp/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances = [4, 10, 20]\n",
    "rotations = [0, np.pi/6, np.pi/2]\n",
    "nrot  = len(rotations)\n",
    "ndist = len(distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 10/94 [00:14<01:48,  1.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting the estimation of properties with subhalo particles for galaxy 114388\n",
      "Starting the estimation of properties with halo particles for galaxy 114388\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_542708/2238376362.py:464: RuntimeWarning: invalid value encountered in power\n",
      "  stars_t0 = 13.8 * (1. - stars_SFT**1.5) + 1e-6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance = 4.00e+00 Theta = 0.00\n",
      "02/12/2024 14:34:13.298   Welcome to SKIRT v9.0 (git 8765014 built on 23/10/2024 at 17:15:30)\n",
      "02/12/2024 14:34:13.298   Running on coglians.phys.sissa.it for mdelosri\n",
      "02/12/2024 14:34:13.299   Constructing a simulation from ski file '/u/m/mdelosri/MaDaMe/data/tmp/galaxy.ski'...\n",
      "\u001b[32m02/12/2024 14:36:48.457 - Finished setup in 155 s (2m 35s).\n",
      "\u001b[0m\u001b[32m02/12/2024 14:36:48.457 - Finished setup output in 0.0 s.\n",
      "\u001b[0m\u001b[32m02/12/2024 14:38:50.886 - Finished primary emission in 122 s (2m 2s).\n",
      "\u001b[0m\u001b[32m02/12/2024 14:38:57.923 - Finished secondary emission in 7.0 s.\n",
      "\u001b[0m\u001b[32m02/12/2024 14:38:57.923 - Finished the run in 129 s (2m 9s).\n",
      "\u001b[0m\u001b[32m02/12/2024 14:39:02.460 - Finished final output in 4.5 s.\n",
      "\u001b[0m\u001b[32m02/12/2024 14:39:02.460 - Finished simulation galaxy using 4 threads and a single process in 289 s (4m 49s).\n",
      "\u001b[0m02/12/2024 14:39:02.678   Available memory: 125 GB -- Peak memory usage: 7.08 GB (5.6%)\n",
      "Source module contained 4249442 particles with total HI mass of 1.19e+11 solMass.\n",
      "Pruned particles that will not contribute to data cube, 115796 particles remaining with total HI mass of 4.57e+10 solMass.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 163216/163216 [16:33<00:00, 164.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source inserted.\n",
      "  Flux density in cube: 7.24e+02 Jy\n",
      "  Mass in cube (assuming distance 4.00 Mpc and a spatially resolved source): 4.37e+10 solMass\n",
      "    [37% of initial source mass]\n",
      "  Maximum pixel: 9.43e-05 Jy / arcsec2\n",
      "  Median non-zero pixel: 8.99e-15 Jy / arcsec2\n",
      "Noise added.\n",
      "  Noise cube RMS: 1.46e-10 Jy / arcsec2 (before beam convolution).\n",
      "  Data cube RMS after noise addition (before beam convolution): 3.96e-06 Jy / arcsec2\n",
      "Beam convolved.\n",
      "  Data cube RMS after beam convolution: 4.09e-03 Jy / beam\n",
      "  Maximum pixel: 8.69e-02 Jy / beam\n",
      "  Median non-zero pixel: 5.34e-08 Jy / beam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 10/94 [24:26<3:25:18, 146.64s/it]\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../data/tmp/HIEmission_SubID_114388__d_4.0_theta_0.00.fits'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 663\u001b[0m\n\u001b[1;32m    660\u001b[0m M\u001b[38;5;241m.\u001b[39mwrite_fits(tmp_folder \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHIEmission_SubID_\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m_d_\u001b[39m\u001b[38;5;132;01m{:.1f}\u001b[39;00m\u001b[38;5;124m_theta_\u001b[39m\u001b[38;5;132;01m{:.2f}\u001b[39;00m\u001b[38;5;124m.fits\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(ids, D, theta))\n\u001b[1;32m    662\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m make_png:\n\u001b[0;32m--> 663\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mfits\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtmp_folder\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mHIEmission_SubID_\u001b[39;49m\u001b[38;5;132;43;01m{}\u001b[39;49;00m\u001b[38;5;124;43m__d_\u001b[39;49m\u001b[38;5;132;43;01m{:.1f}\u001b[39;49;00m\u001b[38;5;124;43m_theta_\u001b[39;49m\u001b[38;5;132;43;01m{:.2f}\u001b[39;49;00m\u001b[38;5;124;43m.fits\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mD\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtheta\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m    664\u001b[0m         cube_wcs   \u001b[38;5;241m=\u001b[39m WCS(f[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mheader)\n\u001b[1;32m    665\u001b[0m         flux_cube  \u001b[38;5;241m=\u001b[39m f[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m*\u001b[39m U\u001b[38;5;241m.\u001b[39mUnit(f[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mheader[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBUNIT\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "File \u001b[0;32m~/miniconda3/envs/martini/lib/python3.9/site-packages/astropy/io/fits/hdu/hdulist.py:222\u001b[0m, in \u001b[0;36mfitsopen\u001b[0;34m(name, mode, memmap, save_backup, cache, lazy_load_hdus, ignore_missing_simple, use_fsspec, fsspec_kwargs, decompress_in_memory, **kwargs)\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m name:\n\u001b[1;32m    220\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEmpty filename: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 222\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mHDUList\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfromfile\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    223\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    224\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    225\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemmap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    226\u001b[0m \u001b[43m    \u001b[49m\u001b[43msave_backup\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    227\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    228\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlazy_load_hdus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    229\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_missing_simple\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    230\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_fsspec\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_fsspec\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    231\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfsspec_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfsspec_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    232\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecompress_in_memory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecompress_in_memory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    233\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    234\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/martini/lib/python3.9/site-packages/astropy/io/fits/hdu/hdulist.py:486\u001b[0m, in \u001b[0;36mHDUList.fromfile\u001b[0;34m(cls, fileobj, mode, memmap, save_backup, cache, lazy_load_hdus, ignore_missing_simple, **kwargs)\u001b[0m\n\u001b[1;32m    467\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m    468\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfromfile\u001b[39m(\n\u001b[1;32m    469\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    477\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    478\u001b[0m ):\n\u001b[1;32m    479\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    480\u001b[0m \u001b[38;5;124;03m    Creates an `HDUList` instance from a file-like object.\u001b[39;00m\n\u001b[1;32m    481\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    484\u001b[0m \u001b[38;5;124;03m    documentation for details of the parameters accepted by this method).\u001b[39;00m\n\u001b[1;32m    485\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 486\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_readfrom\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    487\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfileobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfileobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmemmap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmemmap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    490\u001b[0m \u001b[43m        \u001b[49m\u001b[43msave_backup\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_backup\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    491\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    492\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_missing_simple\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_missing_simple\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlazy_load_hdus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlazy_load_hdus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    495\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/martini/lib/python3.9/site-packages/astropy/io/fits/hdu/hdulist.py:1169\u001b[0m, in \u001b[0;36mHDUList._readfrom\u001b[0;34m(cls, fileobj, data, mode, memmap, cache, lazy_load_hdus, ignore_missing_simple, use_fsspec, fsspec_kwargs, decompress_in_memory, **kwargs)\u001b[0m\n\u001b[1;32m   1166\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fileobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1167\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(fileobj, _File):\n\u001b[1;32m   1168\u001b[0m         \u001b[38;5;66;03m# instantiate a FITS file object (ffo)\u001b[39;00m\n\u001b[0;32m-> 1169\u001b[0m         fileobj \u001b[38;5;241m=\u001b[39m \u001b[43m_File\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1170\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfileobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1171\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1172\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmemmap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmemmap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1173\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1174\u001b[0m \u001b[43m            \u001b[49m\u001b[43muse_fsspec\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_fsspec\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1175\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfsspec_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfsspec_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1176\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdecompress_in_memory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecompress_in_memory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1177\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1178\u001b[0m     \u001b[38;5;66;03m# The Astropy mode is determined by the _File initializer if the\u001b[39;00m\n\u001b[1;32m   1179\u001b[0m     \u001b[38;5;66;03m# supplied mode was None\u001b[39;00m\n\u001b[1;32m   1180\u001b[0m     mode \u001b[38;5;241m=\u001b[39m fileobj\u001b[38;5;241m.\u001b[39mmode\n",
      "File \u001b[0;32m~/miniconda3/envs/martini/lib/python3.9/site-packages/astropy/io/fits/file.py:218\u001b[0m, in \u001b[0;36m_File.__init__\u001b[0;34m(self, fileobj, mode, memmap, overwrite, cache, use_fsspec, fsspec_kwargs, decompress_in_memory)\u001b[0m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_open_fileobj(fileobj, mode, overwrite)\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(fileobj, (\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mbytes\u001b[39m)):\n\u001b[0;32m--> 218\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_open_filename\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfileobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moverwrite\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    219\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    220\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_open_filelike(fileobj, mode, overwrite)\n",
      "File \u001b[0;32m~/miniconda3/envs/martini/lib/python3.9/site-packages/astropy/io/fits/file.py:641\u001b[0m, in \u001b[0;36m_File._open_filename\u001b[0;34m(self, filename, mode, overwrite)\u001b[0m\n\u001b[1;32m    638\u001b[0m ext \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39msplitext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname)[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    640\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_try_read_compressed(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname, magic, mode, ext\u001b[38;5;241m=\u001b[39mext):\n\u001b[0;32m--> 641\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIO_FITS_MODES\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    642\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose_on_error \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    644\u001b[0m \u001b[38;5;66;03m# Make certain we're back at the beginning of the file\u001b[39;00m\n\u001b[1;32m    645\u001b[0m \u001b[38;5;66;03m# BZ2File does not support seek when the file is open for writing, but\u001b[39;00m\n\u001b[1;32m    646\u001b[0m \u001b[38;5;66;03m# when opening a file for write, bz2.BZ2File always truncates anyway.\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../data/tmp/HIEmission_SubID_114388__d_4.0_theta_0.00.fits'"
     ]
    }
   ],
   "source": [
    "force_rerun = False\n",
    "make_png = True\n",
    "\n",
    "file = '../data/gals_properties.h5'\n",
    "\n",
    "nsubhalos = 200\n",
    "properties = np.zeros((1, 17))\n",
    "\n",
    "rmax = 1000 # kPc\n",
    "# 0: ID\n",
    "# 1: central (1 if central, 0 if not)\n",
    "# 2: SubMass [Msun]\n",
    "# 3: SubSFR\n",
    "# 4: SubHMR [kPc]\n",
    "# 5: x [kPc]\n",
    "# 6: y [kPc]\n",
    "# 7: z [kPc]\n",
    "# 8: vx [km/s]\n",
    "# 9: vy [km/s]\n",
    "# 10: vz [km/s]\n",
    "# 11: SubVmax [km/s]\n",
    "# 12: SubVmaxR [kPc]\n",
    "# 13: SubHMRG [kPc] Comoving radius containing half of the mass of this Subhalo \n",
    "                    # split by Type (SubhaloMassType). Type 4 = gas\n",
    "# 14: costheta. Cosine of the angle between the angular momenta and the main axis\n",
    "                # of the inertia tensor.\n",
    "# 15: kappa_AM\n",
    "# 16: kappa_IT\n",
    "\n",
    "nmax = 1\n",
    "ni = 0\n",
    "with h5py.File(file, 'a') as data:\n",
    "    for i in tqdm(range(106,nsubhalos)):\n",
    "        ids = subhalos['results'][i]['id']\n",
    "        \n",
    "        # Let's load the data of the subhalos\n",
    "        sub_meta = get(subhalos['results'][i]['url'])    \n",
    "        # --------------------------------------------------------\n",
    "    \n",
    "        if 'SubID_' + str(ids) in data.keys():\n",
    "            flag_gr = False # This means that we do not have to analyze the group\n",
    "            print('Subhalo ' + str(ids) + ' already exists')\n",
    "            if not data['SubID_' + str(ids)].attrs['done']:\n",
    "                print('The analysis of the subhalo was not finished OK, so we have to do it again :(')\n",
    "                flag_gr = True # This means that we have to analyze the group\n",
    "                del data['SubID_' + str(ids)]\n",
    "                gr = data.create_group('SubID_' + str(ids))\n",
    "            if force_rerun:\n",
    "                flag_gr = True\n",
    "                print('Analysis forced to be run again!')\n",
    "        else:\n",
    "            if ids == get(get(sub_meta['related']['parent_halo'])['meta']['info'])['GroupFirstSub']: # Keep only central galaxies           \n",
    "                gr = data.create_group('SubID_' + str(ids))\n",
    "                flag_gr = True # This means that we have to analyze the group\n",
    "                gr.attrs['done'] = False\n",
    "            else:\n",
    "                flag_gr = False # This means that we do not have to analyze the group\n",
    "        \n",
    "        if flag_gr:\n",
    "            start = time.time()\n",
    "            folder = '../data/TNGgalaxies/' + str(ids)\n",
    "            if not os.path.exists(folder):\n",
    "                os.makedirs(folder)\n",
    "            \n",
    "            # Let's save the main properties  ------------------------           \n",
    "            properties[0, 0] = ids   \n",
    "            gid = sub_meta['grnr'] # sub_meta['SubhaloGrNr']\n",
    "            properties[0, 1] = gid\n",
    "            properties[0, 2] = sub_meta['mass'] * 1e10 / h # [Msun] #sub_meta['SubhaloMass'] * 1e10 / h\n",
    "            properties[0, 3] = sub_meta['sfr'] # [Msun/yr] # sub_meta['SubhaloSFR']\n",
    "            properties[0, 4] = sub_meta['halfmassrad'] / h # [kPc]  # sub_meta['SubhaloHalfmassRad'] / h\n",
    "            properties[0, 5] = sub_meta['pos_x'] / h # [kPc]  # sub_meta['SubhaloPos'][0] / h\n",
    "            properties[0, 6] = sub_meta['pos_y'] / h # [kPc]  # sub_meta['SubhaloPos'][1] / h\n",
    "            properties[0, 7] = sub_meta['pos_z'] / h # [kPc]  # sub_meta['SubhaloPos'][2] / h\n",
    "            properties[0, 8] = sub_meta['vel_x'] # [km/s] # sub_meta['SubhaloVel'][0]\n",
    "            properties[0, 9] = sub_meta['vel_y'] # [km/s] # sub_meta['SubhaloVel'][1]\n",
    "            properties[0, 10] = sub_meta['vel_z'] # [km/s] # sub_meta['SubhaloVel'][2]\n",
    "            properties[0, 11] = sub_meta['vmax'] # [km/s] # sub_meta['SubhaloVmax']\n",
    "            properties[0, 12] = sub_meta['vmaxrad'] / h # [kPc] # sub_meta['SubhaloVmaxRad'] / h\n",
    "            properties[0, 13] = sub_meta['halfmassrad_stars'] / h # [kPc] # sub_meta['SubhaloHalfmassRadType'][4] / h\n",
    "    \n",
    "            # --------------------------------------------------------\n",
    "    \n",
    "            # Let's estimate properties with the particles of the subhalos\n",
    "            print('Starting the estimation of properties with subhalo particles for galaxy ' + str(ids))\n",
    "            sub_data_url = subhalos['results'][i]['url'] + 'vis.hdf5'\n",
    "            center_sub   = properties[0, 5:8]\n",
    "            velocity     = properties[0, 8:11]    \n",
    "            \n",
    "            stars_subhalo = get(subhalos['results'][i]['url'] + '/' + 'cutout.hdf5', \n",
    "                               {'stars':'Coordinates,GFM_InitialMass,GFM_Metallicity,GFM_StellarFormationTime,Masses,StellarHsml,Velocities'})\n",
    "            stars_c = stars_subhalo[0] / h\n",
    "            stars_v = stars_subhalo[6]\n",
    "            stars_m = stars_subhalo[4] * 1e10 / h\n",
    "            try:\n",
    "                gas_subhalo = get(subhalos['results'][i]['url'] + '/' + 'cutout.hdf5', \n",
    "                       {'gas':'coordinates,density,ElectronAbundance,GFM_Metallicity,GFM_Metals,InternalEnergy,masses,SubfindHsml,velocities'})\n",
    "    \n",
    "                gas_c   = gas_subhalo[0] / h\n",
    "                gas_v   = gas_subhalo[8]\n",
    "                gas_m   = gas_subhalo[6] * 1e10 / h\n",
    "                gas_HI  = gas_subhalo[4][:,0]\n",
    "                flag_gas = True\n",
    "            except:\n",
    "                print('Galaxy ' + str(ids) + ' have no gas')\n",
    "                flag_gas = False\n",
    "            dm_c    = get(subhalos['results'][i]['url'] + 'cutout.hdf5', {'dm':'Coordinates'})[0] / h\n",
    "            dm_v    = get(subhalos['results'][i]['url'] + 'cutout.hdf5', {'dm':'Velocities'})[0]\n",
    "    \n",
    "            # Let's move the coordinates if they are near the border\n",
    "            aux_ind = np.where( (stars_c[:, 0] - center_sub[0]) > (box_size / 2) )[0]\n",
    "            stars_c[aux_ind, 0] = stars_c[aux_ind, 0] - box_size\n",
    "            aux_ind = np.where( (center_sub[0] - stars_c[:, 0]) > (box_size / 2) )[0]\n",
    "            stars_c[aux_ind, 0] = stars_c[aux_ind, 0] + box_size\n",
    "            aux_ind = np.where( (stars_c[:, 1] - center_sub[1]) > (box_size / 2) )[0]\n",
    "            stars_c[aux_ind, 1] = stars_c[aux_ind, 1] - box_size\n",
    "            aux_ind = np.where( (center_sub[1] - stars_c[:, 1]) > (box_size / 2) )[0]\n",
    "            stars_c[aux_ind, 1] = stars_c[aux_ind, 1] + box_size\n",
    "            aux_ind = np.where( (stars_c[:, 2] - center_sub[2]) > (box_size / 2) )[0]\n",
    "            stars_c[aux_ind, 2] = stars_c[aux_ind, 2] - box_size\n",
    "            aux_ind = np.where( (center_sub[2] - stars_c[:, 2]) > (box_size / 2) )[0]\n",
    "            stars_c[aux_ind, 2] = stars_c[aux_ind, 2] + box_size\n",
    "            \n",
    "            if flag_gas:\n",
    "                aux_ind = np.where( (gas_c[:, 0] - center_sub[0]) > (box_size / 2) )[0]\n",
    "                gas_c[aux_ind, 0] = gas_c[aux_ind, 0] - box_size\n",
    "                aux_ind = np.where( (center_sub[0] - gas_c[:, 0]) > (box_size / 2) )[0]\n",
    "                gas_c[aux_ind, 0] = gas_c[aux_ind, 0] + box_size\n",
    "                aux_ind = np.where( (gas_c[:, 1] - center_sub[1]) > (box_size / 2) )[0]\n",
    "                gas_c[aux_ind, 1] = gas_c[aux_ind, 1] - box_size\n",
    "                aux_ind = np.where( (center_sub[1] - gas_c[:, 1]) > (box_size / 2) )[0]\n",
    "                gas_c[aux_ind, 1] = gas_c[aux_ind, 1] + box_size\n",
    "                aux_ind = np.where( (gas_c[:, 2] - center_sub[2]) > (box_size / 2) )[0]\n",
    "                gas_c[aux_ind, 2] = gas_c[aux_ind, 2] - box_size\n",
    "                aux_ind = np.where( (center_sub[2] - gas_c[:, 2]) > (box_size / 2) )[0]\n",
    "                gas_c[aux_ind, 2] = gas_c[aux_ind, 2] + box_size\n",
    "                \n",
    "            aux_ind = np.where( (dm_c[:, 0] - center_sub[0]) > (box_size / 2) )[0]\n",
    "            dm_c[aux_ind, 0] = dm_c[aux_ind, 0] - box_size\n",
    "            aux_ind = np.where( (center_sub[0] - dm_c[:, 0]) > (box_size / 2) )[0]\n",
    "            dm_c[aux_ind, 0] = dm_c[aux_ind, 0] + box_size\n",
    "            aux_ind = np.where( (dm_c[:, 1] - center_sub[1]) > (box_size / 2) )[0]\n",
    "            dm_c[aux_ind, 1] = dm_c[aux_ind, 1] - box_size\n",
    "            aux_ind = np.where( (center_sub[1] - dm_c[:, 1]) > (box_size / 2) )[0]\n",
    "            dm_c[aux_ind, 1] = dm_c[aux_ind, 1] + box_size\n",
    "            aux_ind = np.where( (dm_c[:, 2] - center_sub[2]) > (box_size / 2) )[0]\n",
    "            dm_c[aux_ind, 2] = dm_c[aux_ind, 2] - box_size\n",
    "            aux_ind = np.where( (center_sub[2] - dm_c[:, 2]) > (box_size / 2) )[0]\n",
    "            dm_c[aux_ind, 2] = dm_c[aux_ind, 2] + box_size\n",
    "            # --------------------------------------------------------\n",
    "            \n",
    "            # ------------------Let's center the particles -----------\n",
    "            stars_c = stars_c - center_sub\n",
    "            stars_v = stars_v - velocity\n",
    "            \n",
    "            dm_v = dm_v - velocity\n",
    "            dm_c = dm_c - center_sub\n",
    "            \n",
    "            if flag_gas:\n",
    "                gas_c = gas_c - center_sub\n",
    "                gas_v = gas_v - velocity\n",
    "            # --------------------------------------------------------\n",
    "                  \n",
    "            # Let's Compute the distance of each DM particle to the center and sum in radial bins\n",
    "            dist = np.linalg.norm(dm_c, axis=1)\n",
    "            M = np.array([len(np.where(np.array(dist) < R)[0]) * M_dm for R in R_bins])\n",
    "            if rmax == None: rmax = (3 * properties[0, 4]) # max radii for saving particles\n",
    "            ind_dm = np.where(np.array(dist) < rmax)[0] # for saving only close particles\n",
    "            # --------------------------------------------------------\n",
    "    \n",
    "            # Let's Compute the distance of each star particle to the center and sum in radial bins\n",
    "            dist = np.linalg.norm(stars_c, axis=1)\n",
    "            M_stars = np.array([np.sum( stars_m[np.where(np.array(dist) < R)[0]] ) for R in R_bins])\n",
    "            ind_stars = np.where(np.array(dist) < rmax)[0] # for saving only close particles\n",
    "            # --------------------------------------------------------\n",
    "    \n",
    "            # Compute the distance of each particle to the center and sum in radial bins\n",
    "            if flag_gas:\n",
    "                dist = np.linalg.norm(gas_c, axis=1)\n",
    "                M_gas = np.array([np.sum( gas_m[np.where(np.array(dist) < R)[0]] ) for R in R_bins])\n",
    "                ind_gas = np.where(np.array(dist) < rmax)[0] # for saving only close particles\n",
    "            # --------------------------------------------------------\n",
    "            \n",
    "            # Let's save the data of these profiles\n",
    "            gr.create_dataset('R_bins_sub', data = R_bins)\n",
    "            gr.create_dataset('M_DM_sub', data = M)\n",
    "            gr.create_dataset('M_stars_sub', data = M_stars)   \n",
    "            if flag_gas:\n",
    "                gr.create_dataset('M_gas_sub', data = M_gas)\n",
    "            # --------------------------------------------------------\n",
    "    \n",
    "            # Let's compute the rotation matrix taking into accunt the inertia tensor\n",
    "            rot_mat_IT, L_IT = compute_rot_mat_inertia(np.zeros(3), stars_c, stars_m, Rmax = 2 * properties[0, 13])\n",
    "            # --------------------------------------------------------\n",
    "    \n",
    "            # Let's compute the rotation matrix taking into accunt the angular momentum tensor\n",
    "            rot_mat_AM, L_AM = compute_rot_mat_angMom(np.zeros(3), stars_c, stars_v, stars_m, Rmax = 2 * properties[0, 13])\n",
    "            # --------------------------------------------------------\n",
    "    \n",
    "            # Let's rotate the coordiantes with AM\n",
    "            dm_c_rot_AM = dm_c @ rot_mat_AM\n",
    "            dm_v_rot_AM = dm_v @ rot_mat_AM\n",
    "            stars_c_rot_AM = stars_c @ rot_mat_AM\n",
    "            stars_v_rot_AM = stars_v @ rot_mat_AM\n",
    "            if flag_gas:\n",
    "                gas_c_rot_AM = gas_c @ rot_mat_AM\n",
    "                gas_v_rot_AM = gas_v @ rot_mat_AM\n",
    "    \n",
    "            L_AM_rot_AM = L_AM @ rot_mat_AM\n",
    "            L_IT_rot_AM = L_IT @ rot_mat_AM\n",
    "            # --------------------------------------------------------\n",
    "    \n",
    "            # Let's rotate the coordiantes with IT\n",
    "            dm_c_rot_IT = dm_c @ rot_mat_IT\n",
    "            dm_v_rotv = dm_v @ rot_mat_IT\n",
    "            stars_c_rot_IT = stars_c @ rot_mat_IT\n",
    "            stars_v_rot_IT = stars_v @ rot_mat_IT\n",
    "            if flag_gas:\n",
    "                gas_c_rot_IT = gas_c @ rot_mat_IT\n",
    "                gas_v_rot_IT = gas_v @ rot_mat_IT\n",
    "    \n",
    "            L_AM_rot_IT = L_AM @ rot_mat_IT\n",
    "            L_IT_rot_IT = L_IT @ rot_mat_IT\n",
    "            # --------------------------------------------------------\n",
    "    \n",
    "            # Let's aligendthe stars with the IT\n",
    "            x_stars_IT  = stars_c_rot_IT[:,0]\n",
    "            y_stars_IT  = stars_c_rot_IT[:,1]\n",
    "            z_stars_IT  = stars_c_rot_IT[:,2]\n",
    "            vx_stars_IT = stars_v_rot_IT[:,0]\n",
    "            vy_stars_IT = stars_v_rot_IT[:,1]\n",
    "            vz_stars_IT = stars_v_rot_IT[:,2]\n",
    "            # --------------------------------------------------------\n",
    "    \n",
    "    \n",
    "            # Let's move to cylindrical coordinates and the kinematical properties\n",
    "            r_stars_IT         = np.sqrt(x_stars_IT**2 + y_stars_IT**2)\n",
    "            phi_stars_IT       = np.arctan2(y_stars_IT, x_stars_IT)\n",
    "            jz_stars_IT        = x_stars_IT * vy_stars_IT - y_stars_IT * vx_stars_IT\n",
    "            Erot_stars_IT      = stars_m * (jz_stars_IT**2) / (r_stars_IT**2)\n",
    "            Ek_stars_IT        = stars_m * (vx_stars_IT**2 + vy_stars_IT**2 + vz_stars_IT**2)\n",
    "            kappa_stars_IT     = np.sum(Erot_stars_IT) / np.sum(Ek_stars_IT)\n",
    "            vphi_full_stars_IT = jz_stars_IT / r_stars_IT\n",
    "            # --------------------------------------------------------\n",
    "    \n",
    "    \n",
    "            # Now aligend the stars with the AM\n",
    "    \n",
    "            x_stars_AM  = stars_c_rot_AM[:,0]\n",
    "            y_stars_AM  = stars_c_rot_AM[:,1]\n",
    "            z_stars_AM  = stars_c_rot_AM[:,2]\n",
    "            vx_stars_AM = stars_v_rot_AM[:,0]\n",
    "            vy_stars_AM = stars_v_rot_AM[:,1]\n",
    "            vz_stars_AM = stars_v_rot_AM[:,2]\n",
    "            # --------------------------------------------------------\n",
    "    \n",
    "            # Let's move to cylindrical coordinates and the kinematical properties\n",
    "            r_stars_AM     = np.sqrt(x_stars_AM**2 + y_stars_AM**2)\n",
    "            phi_stars_AM   = np.arctan2(y_stars_AM, x_stars_AM)\n",
    "            jz_stars_AM    = x_stars_AM * vy_stars_AM - y_stars_AM * vx_stars_AM\n",
    "            Erot_stars_AM  = stars_m * (jz_stars_AM**2) / (r_stars_AM**2)\n",
    "            Ek_stars_AM    = stars_m * (vx_stars_AM**2 + vy_stars_AM**2 + vz_stars_AM**2)\n",
    "            kappa_stars_AM = np.sum(Erot_stars_AM) / np.sum(Ek_stars_AM)\n",
    "            vphi_full_stars_AM = jz_stars_AM / r_stars_AM\n",
    "            # --------------------------------------------------------\n",
    "    \n",
    "            # Let's save the main properties\n",
    "            properties[0, 14] = np.dot(L_IT, L_AM) / ( np.linalg.norm(L_IT) * np.linalg.norm(L_AM) )\n",
    "            properties[0, 15] = kappa_stars_AM\n",
    "            properties[0, 16] = kappa_stars_IT\n",
    "            # --------------------------------------------------------\n",
    "            gr.create_dataset('Props', data = properties[0,:])\n",
    "    \n",
    "            # Let's compute rotation curve with gas\n",
    "    \n",
    "            # Let's aligend the gas with the IT\n",
    "            if flag_gas:\n",
    "                x_gas_IT  = gas_c_rot_IT[:,0]\n",
    "                y_gas_IT  = gas_c_rot_IT[:,1]\n",
    "                z_gas_IT  = gas_c_rot_IT[:,2]\n",
    "                vx_gas_IT = gas_v_rot_IT[:,0]\n",
    "                vy_gas_IT = gas_v_rot_IT[:,1]\n",
    "                vz_gas_IT = gas_v_rot_IT[:,2]\n",
    "                # --------------------------------------------------------\n",
    "    \n",
    "                # Let's move to cylindrical coordinates and compute the kinematical properties\n",
    "                r_gas_IT         = np.sqrt(x_gas_IT**2 + y_gas_IT**2)\n",
    "                phi_gas_IT       = np.arctan2(y_gas_IT, x_gas_IT)\n",
    "                jz_gas_IT        = x_gas_IT * vy_gas_IT - y_gas_IT * vx_gas_IT\n",
    "                Erot_gas_IT      = gas_m * (jz_gas_IT**2) / (r_gas_IT**2)\n",
    "                Ek_gas_IT        = gas_m * (vx_gas_IT**2 + vy_gas_IT**2 + vz_gas_IT**2)\n",
    "                kappa_gas_IT     = np.sum(Erot_gas_IT) / np.sum(Ek_gas_IT)\n",
    "                vphi_full_gas_IT = jz_gas_IT / r_gas_IT\n",
    "                # --------------------------------------------------------\n",
    "    \n",
    "                # Now let's aligend the gas with the AM\n",
    "    \n",
    "                x_gas_AM  = gas_c_rot_AM[:,0]\n",
    "                y_gas_AM  = gas_c_rot_AM[:,1]\n",
    "                z_gas_AM  = gas_c_rot_AM[:,2]\n",
    "                vx_gas_AM = gas_v_rot_AM[:,0]\n",
    "                vy_gas_AM = gas_v_rot_AM[:,1]\n",
    "                vz_gas_AM = gas_v_rot_AM[:,2]\n",
    "    \n",
    "                # Let's move to cylindrical coordinates and compute the kinematical properties\n",
    "                r_gas_AM     = np.sqrt(x_gas_AM**2 + y_gas_AM**2)\n",
    "                phi_gas_AM   = np.arctan2(y_gas_AM, x_gas_AM)\n",
    "                jz_gas_AM    = x_gas_AM * vy_gas_AM - y_gas_AM * vx_gas_AM\n",
    "                Erot_gas_AM  = gas_m * (jz_gas_AM**2) / (r_gas_AM**2)\n",
    "                Ek_gas_AM    = gas_m * (vx_gas_AM**2 + vy_gas_AM**2 + vz_gas_AM**2)\n",
    "                kappa_gas_AM = np.sum(Erot_gas_AM) / np.sum(Ek_gas_AM)\n",
    "                vphi_full_gas_AM = jz_gas_AM / r_gas_AM\n",
    "                # --------------------------------------------------------\n",
    "    \n",
    "                # Let's compute the binned rotational curves and saved it\n",
    "                v_rot_gas_IT, bin_edges,_ = binned_statistic(r_gas_IT, np.abs(vphi_full_gas_IT), 'mean', bins = R_bins)\n",
    "                v_std_gas_IT,_,_ = binned_statistic(r_gas_IT, np.abs(vphi_full_gas_IT), 'std', bins = R_bins)\n",
    "                v_rot_gas_AM,_,_ = binned_statistic(r_gas_AM, np.abs(vphi_full_gas_AM), 'mean', bins = R_bins)\n",
    "                v_std_gas_AM,_,_ = binned_statistic(r_gas_AM, np.abs(vphi_full_gas_IT), 'std', bins = R_bins)\n",
    "    \n",
    "            v_rot_stars_IT, bin_edges,_  = binned_statistic(r_stars_IT, np.abs(vphi_full_stars_IT), 'mean', bins = R_bins)\n",
    "            v_std_stars_IT,_,_ = binned_statistic(r_stars_IT, np.abs(vphi_full_stars_IT), 'std', bins = R_bins)\n",
    "            v_rot_stars_AM,_,_ = binned_statistic(r_stars_AM, np.abs(vphi_full_stars_AM), 'mean', bins = R_bins)\n",
    "            v_std_stars_AM,_,_ = binned_statistic(r_stars_AM, np.abs(vphi_full_stars_AM), 'std', bins = R_bins)\n",
    "    \n",
    "            bin_width = (bin_edges[1] - bin_edges[0])\n",
    "            bin_centers = bin_edges[1:] - bin_width/2\n",
    "    \n",
    "            gr.create_dataset('R_bins_vels', data = bin_centers)\n",
    "            if flag_gas:\n",
    "                gr.create_dataset('V_rot_gas_IT', data = v_rot_gas_IT)\n",
    "                gr.create_dataset('V_std_gas_IT', data = v_std_gas_IT)\n",
    "                gr.create_dataset('V_rot_gas_AM', data = v_rot_gas_AM)\n",
    "                gr.create_dataset('V_std_gas_AM', data = v_std_gas_AM)\n",
    "            gr.create_dataset('V_rot_stars_IT', data = v_rot_stars_IT)\n",
    "            gr.create_dataset('V_std_stars_IT', data = v_std_stars_IT)\n",
    "            gr.create_dataset('V_rot_stars_AM', data = v_rot_stars_AM)\n",
    "            gr.create_dataset('V_std_stars_AM', data = v_std_stars_AM)\n",
    "            # ---------------------------------------------------------------------------------------\n",
    "    \n",
    "            # Let's estimate the real profiles taking into account the halo\n",
    "            print('Starting the estimation of properties with halo particles for galaxy ' + str(ids))\n",
    "    \n",
    "            # Let's load the DM particles of the halo to which the subhalo belongs\n",
    "            dm_halo = get('http://www.tng-project.org/api/TNG100-1/snapshots/99/halos/' + str(gid) + '/' + 'cutout.hdf5', {'dm':'coordinates'})[0] / h\n",
    "            \n",
    "            # ---------------------------------------------------------------------------------------\n",
    "    \n",
    "            # If the halo is near the border let's center it\n",
    "            aux_ind = np.where( (dm_halo[:, 0] - center_sub[0]) > (box_size / 2) )[0]\n",
    "            dm_halo[aux_ind, 0] = dm_halo[aux_ind, 0] - box_size\n",
    "            aux_ind = np.where( (center_sub[0] - dm_halo[:, 0]) > (box_size / 2) )[0]\n",
    "            dm_halo[aux_ind, 0] = dm_halo[aux_ind, 0] + box_size\n",
    "            aux_ind = np.where( (dm_halo[:, 1] - center_sub[1]) > (box_size / 2) )[0]\n",
    "            dm_halo[aux_ind, 1] = dm_halo[aux_ind, 1] - box_size\n",
    "            aux_ind = np.where( (center_sub[1] - dm_halo[:, 1]) > (box_size / 2) )[0]\n",
    "            dm_halo[aux_ind, 1] = dm_halo[aux_ind, 1] + box_size\n",
    "            aux_ind = np.where( (dm_halo[:, 2] - center_sub[2]) > (box_size / 2) )[0]\n",
    "            dm_halo[aux_ind, 2] = dm_halo[aux_ind, 2] - box_size\n",
    "            aux_ind = np.where( (center_sub[2] - dm_halo[:, 2]) > (box_size / 2) )[0]\n",
    "            dm_halo[aux_ind, 2] = dm_halo[aux_ind, 2] + box_size\n",
    "            # ---------------------------------------------------------------------------------------\n",
    "            # ----------------------Let's center de coords---------------------\n",
    "            dm_halo = dm_halo - center_sub\n",
    "            # -----------------------------------------------------------------\n",
    "            # Compute the distance of each particle to the center and sum in radial bins\n",
    "            dist = np.linalg.norm(dm_halo, axis=1)\n",
    "            M = np.array([len(np.where(np.array(dist) < R)[0]) * M_dm for R in R_bins])\n",
    "            # ---------------------------------------------------------------------------------------\n",
    "    \n",
    "            # Let's load the stars particles of the halo to which the subhalo belongs\n",
    "            \n",
    "            stars_halo = get('http://www.tng-project.org/api/TNG100-1/snapshots/99/halos/' + str(gid) + '/' + 'cutout.hdf5', \n",
    "                               {'stars':'Coordinates,GFM_InitialMass,GFM_Metallicity,GFM_StellarFormationTime,Masses,StellarHsml,Velocities'})\n",
    "            stars_halo_c = stars_halo[0] / h\n",
    "            stars_halo_m = stars_halo[4] * 1e10 / h\n",
    "            stars_halo_v = stars_halo[6]\n",
    "    \n",
    "            # ---------------------------------------------------------------------------------------\n",
    "    \n",
    "            # If the halo is near the border let's center it\n",
    "            aux_ind = np.where( (stars_halo_c[:, 0] - center_sub[0]) > (box_size / 2) )[0]\n",
    "            stars_halo_c[aux_ind, 0] = stars_halo_c[aux_ind, 0] - box_size\n",
    "            aux_ind = np.where( (center_sub[0] - stars_halo_c[:, 0]) > (box_size / 2) )[0]\n",
    "            stars_halo_c[aux_ind, 0] = stars_halo_c[aux_ind, 0] + box_size\n",
    "            aux_ind = np.where( (stars_halo_c[:, 1] - center_sub[1]) > (box_size / 2) )[0]\n",
    "            stars_halo_c[aux_ind, 1] = stars_halo_c[aux_ind, 1] - box_size\n",
    "            aux_ind = np.where( (center_sub[1] - stars_halo_c[:, 1]) > (box_size / 2) )[0]\n",
    "            stars_halo_c[aux_ind, 1] = stars_halo_c[aux_ind, 1] + box_size\n",
    "            aux_ind = np.where( (stars_halo_c[:, 2] - center_sub[2]) > (box_size / 2) )[0]\n",
    "            stars_halo_c[aux_ind, 2] = stars_halo_c[aux_ind, 2] - box_size\n",
    "            aux_ind = np.where( (center_sub[2] - stars_halo_c[:, 2]) > (box_size / 2) )[0]\n",
    "            stars_halo_c[aux_ind, 2] = stars_halo_c[aux_ind, 2] + box_size\n",
    "            \n",
    "            # ----------------------Let's center de coords---------------------\n",
    "            stars_halo_c = stars_halo_c - center_sub\n",
    "            stars_halo_v = stars_halo_v - velocity\n",
    "            # ---------------------------------------------------------------------------------------\n",
    "    \n",
    "            # Compute the distance of each particle to the center and sum in radial bins\n",
    "            dist = np.linalg.norm(stars_halo_c, axis=1)\n",
    "            M_stars = np.array([np.sum( stars_halo_m[np.where(np.array(dist) < R)[0]] ) for R in R_bins])\n",
    "            ind_stars = np.where(np.array(dist) < rmax)[0] # Keep only close particles\n",
    "            # ---------------------------------------------------------------------------------------\n",
    "    \n",
    "            # Let's load the stars particles of the halo to which the subhalo belongs\n",
    "            \n",
    "            gas_halo = get('http://www.tng-project.org/api/TNG100-1/snapshots/99/halos/' + str(gid) + '/' + 'cutout.hdf5', \n",
    "                           {'gas':'coordinates,density,ElectronAbundance,GFM_Metallicity,GFM_Metals,InternalEnergy,masses,SubfindHsml,velocities'})        \n",
    "            gas_halo_c = gas_halo[0] / h\n",
    "            gas_halo_m = gas_halo[6] * 1e10 / h\n",
    "            gas_halo_v = gas_halo[8]\n",
    "            gas_halo_HI = gas_halo[4][:,0]\n",
    "    \n",
    "            # ---------------------------------------------------------------------------------------\n",
    "    \n",
    "            # If the halo is near the border let's center it\n",
    "            aux_ind = np.where( (gas_halo_c[:, 0] - center_sub[0]) > (box_size / 2) )[0]\n",
    "            gas_halo_c[aux_ind, 0] = gas_halo_c[aux_ind, 0] - box_size\n",
    "            aux_ind = np.where( (center_sub[0] - gas_halo_c[:, 0]) > (box_size / 2) )[0]\n",
    "            gas_halo_c[aux_ind, 0] = gas_halo_c[aux_ind, 0] + box_size\n",
    "            aux_ind = np.where( (gas_halo_c[:, 1] - center_sub[1]) > (box_size / 2) )[0]\n",
    "            gas_halo_c[aux_ind, 1] = gas_halo_c[aux_ind, 1] - box_size\n",
    "            aux_ind = np.where( (center_sub[1] - gas_halo_c[:, 1]) > (box_size / 2) )[0]\n",
    "            gas_halo_c[aux_ind, 1] = gas_halo_c[aux_ind, 1] + box_size\n",
    "            aux_ind = np.where( (gas_halo_c[:, 2] - center_sub[2]) > (box_size / 2) )[0]\n",
    "            gas_halo_c[aux_ind, 2] = gas_halo_c[aux_ind, 2] - box_size\n",
    "            aux_ind = np.where( (center_sub[2] - gas_halo_c[:, 2]) > (box_size / 2) )[0]\n",
    "            gas_halo_c[aux_ind, 2] = gas_halo_c[aux_ind, 2] + box_size\n",
    "            # ----------------------Let's center de coords---------------------\n",
    "            gas_halo_c = gas_halo_c - center_sub        \n",
    "            gas_halo_v = gas_halo_v - velocity\n",
    "            # ---------------------------------------------------------------------------------------\n",
    "    \n",
    "            # Compute the distance of each particle to the center and sum in radial bins\n",
    "            dist = np.linalg.norm(gas_halo_c, axis=1)\n",
    "            M_gas = np.array([np.sum( gas_halo_m[np.where(np.array(dist) < R)[0]] ) for R in R_bins])\n",
    "    \n",
    "            ind_gas = np.where(np.array(dist) < rmax)[0] # Keep only close particles\n",
    "            gr.create_dataset('R_bins', data = R_bins)\n",
    "            gr.create_dataset('M_DM', data = M)\n",
    "            gr.create_dataset('M_stars', data = M_stars)   \n",
    "            gr.create_dataset('M_gas', data = M_gas)\n",
    "            # -------------------------------------------------------------------------------------\n",
    "    \n",
    "            # Let's read the particles and perform the corresponding rotations\n",
    "            stars_particles = stars_halo_c[ind_stars] # [kPc]\n",
    "            npart = len(stars_particles)\n",
    "            \n",
    "            aux = stars_halo[5][ind_stars] / h # Hsml [kPc]\n",
    "            stars_particles = np.hstack((stars_particles, aux.reshape(npart, 1)))\n",
    "            \n",
    "            aux = stars_halo_v[ind_stars] # Vels [km sqrt(a)/s]\n",
    "            stars_particles = np.hstack((stars_particles, aux))\n",
    "            \n",
    "            aux = stars_halo[1][ind_stars] * (1e10) / h # [Msun]\n",
    "            stars_particles = np.hstack((stars_particles, aux.reshape(npart, 1)))\n",
    "            \n",
    "            aux = stars_halo[2][ind_stars]\n",
    "            stars_particles = np.hstack((stars_particles, aux.reshape(npart, 1)))\n",
    "            \n",
    "            stars_SFT = stars_halo[3][ind_stars]\n",
    "            \n",
    "            stars_t0 = 13.8 * (1. - stars_SFT**1.5) + 1e-6\n",
    "            \n",
    "            stars_particles = np.hstack((stars_particles, stars_t0.reshape(npart, 1)))\n",
    "    \n",
    "            # Discard wind particles (definition from illustris documentation) \n",
    "            ind_wind = np.where(stars_SFT <= 0)[0]\n",
    "            if len(ind_wind) > 0:\n",
    "                stars_particles = np.delete(stars_particles, ind_wind, axis=0)\n",
    "                \n",
    "            # Compute the rotation matrix to alig the ang momenta to the z-axis\n",
    "            rot_mat_AM, L_AM = compute_rot_mat_angMom(np.zeros(3), stars_particles[:,0:3], stars_particles[:,4:7], stars_particles[:,8], Rmax = 200)\n",
    "            \n",
    "            # Separare old from young stars:\n",
    "            ind_old = np.where(stars_particles[:,9] > 1e-2)[0]        # from where do we get this condition???\n",
    "            ind_new = np.where(stars_particles[:,9] <= 1e-2)[0]\n",
    "\n",
    "            # Gas partciles\n",
    "                        \n",
    "            gas_particles = gas_halo_c[ind_gas] # [kPc]\n",
    "            gas_npart = len(gas_particles)\n",
    "            \n",
    "            aux = gas_halo[1][ind_gas] * (1e10) * (h**2) # [Msun / kPc^3]\n",
    "            gas_particles = np.hstack((gas_particles, aux.reshape(gas_npart, 1)))\n",
    "            \n",
    "            aux = gas_halo[3][ind_gas]\n",
    "            gas_particles = np.hstack((gas_particles, aux.reshape(gas_npart, 1)))\n",
    "            \n",
    "            aux = gas_halo_v[ind_gas] # Vels [km sqrt(a)/s]\n",
    "            gas_particles = np.hstack((gas_particles, aux))\n",
    "\n",
    "            if 'thetas' in gr.attrs: \n",
    "                thetas = gr.attrs['thetas']\n",
    "            else:\n",
    "                thetas = []\n",
    "            \n",
    "            if 'dists' in gr.attrs: \n",
    "                dists = gr.attrs['dists']\n",
    "            else:\n",
    "                dists = []\n",
    "            \n",
    "            if 'names' in gr.attrs: \n",
    "                names = gr.attrs['names']\n",
    "            else:\n",
    "                names = []\n",
    "                \n",
    "            for idist in range(ndist):\n",
    "                D = distances[idist]\n",
    "                for irot in range(nrot):       \n",
    "                    theta = rotations[irot]\n",
    "                    print('Distance = {:.2e} Theta = {:.2f}'.format(D, theta))\n",
    "                    \n",
    "                    particles = np.copy(stars_particles)\n",
    "                    # Rotate to be edge-on: (SKIRT is observing from z axis, i.e, it observe the plane x-y) \n",
    "                    particles[:,0:3], particles[:,4:7] = rotate(particles = particles[:,0:3], velocities = particles[:,4:7], \n",
    "                                                                theta = theta, rot_mat = rot_mat_AM) # This put the AM in the z-axis\n",
    "                    particles[:,0:3], particles[:,4:7] = rotate(particles = particles[:,0:3], velocities = particles[:,4:7], \n",
    "                                                                theta = theta) # This put the AM in the x-axis to be edge-on on skirt\n",
    "                            \n",
    "                    particles_old = particles[ind_old]\n",
    "                    particles_new = particles[ind_new]\n",
    "                    \n",
    "                    if len(ind_old) > 0:\n",
    "                        np.savetxt(tmp_folder + '/stars_old.txt', particles_old, header = stars_old_header)\n",
    "                        \n",
    "                    if len(ind_new) > 0:\n",
    "                        log10C = np.repeat(5, len(ind_new)).reshape(len(ind_new),1)\n",
    "                        P = np.repeat(0.1, len(ind_new)).reshape(len(ind_new),1)\n",
    "                        ccf = np.repeat(0.2, len(ind_new)).reshape(len(ind_new),1)\n",
    "                        particles_new[:,7] = particles_new[:,7] / particles_new[:,9] * 1e9 # I dont know why we do this\n",
    "                        \n",
    "                        particles_new = np.hstack((particles_new, log10C, P, ccf))\n",
    "                    \n",
    "                        np.savetxt(tmp_folder + '/stars_sb.txt', particles_new, header = stars_sb_header)\n",
    "\n",
    "                    \n",
    "                    # Rotate gas data to be edge-on\n",
    "                    particles = np.copy(gas_particles)\n",
    "                    \n",
    "                    particles[:,0:3], particles[:,5:8] = rotate(particles = particles[:,0:3], velocities = particles[:,5:8], \n",
    "                                                                theta = theta, rot_mat = rot_mat_AM) # This put the AM in the z-axis\n",
    "                    particles[:,0:3], particles[:,5:8] = rotate(particles = particles[:,0:3], velocities = particles[:,5:8], \n",
    "                                                                theta = theta) # This put the AM in the x-axis (to be edge-on in skirt)\n",
    "                    \n",
    "                    # Let's save the data\n",
    "                    particles[:,3] = particles[:,3] * 1e-9 # Convert to [M_sun / Pc^3]\n",
    "                    np.savetxt(tmp_folder + '/gas.txt', particles, header = gas_header)\n",
    "                    # ----------------------------------------------------------------\n",
    "            \n",
    "                    # Let's start with SKIRT\n",
    "                    skifile = sm.SkiFile('template.ski')\n",
    "                    #skifile.setStringAttribute('.//ParticleSource', 'filename', '../../stars_old.txt')\n",
    "                    #skifile.setStringAttribute('.//VoronoiMeshMedium', 'filename', '../../gas.txt')\n",
    "                    \n",
    "                    skifile.setStringAttribute('.//VoronoiMeshMedium', 'minX', str(-Rmedium) + ' pc')\n",
    "                    skifile.setStringAttribute('.//VoronoiMeshMedium', 'maxX', str(Rmedium) + ' pc')\n",
    "                    skifile.setStringAttribute('.//VoronoiMeshMedium', 'minY', str(-Rmedium) + ' pc')\n",
    "                    skifile.setStringAttribute('.//VoronoiMeshMedium', 'maxY', str(Rmedium) + ' pc')\n",
    "                    skifile.setStringAttribute('.//VoronoiMeshMedium', 'minZ', str(-Rmedium) + ' pc')\n",
    "                    skifile.setStringAttribute('.//VoronoiMeshMedium', 'maxZ', str(Rmedium) + ' pc')\n",
    "            \n",
    "                    skifile.setNumPrimaryPackets(2e7)\n",
    "                    skifile.setStringAttribute('.//FrameInstrument', 'distance', str(D) + ' Mpc')\n",
    "                    skifile.setStringAttribute('.//FrameInstrument', 'numPixelsX', str(n_px))\n",
    "                    skifile.setStringAttribute('.//FrameInstrument', 'numPixelsY', str(n_px))\n",
    "                    skifile.setStringAttribute('.//FrameInstrument', 'fieldOfViewX', str(100000) + ' pc')\n",
    "                    skifile.setStringAttribute('.//FrameInstrument', 'fieldOfViewY', str(100000) + ' pc')\n",
    "                    \n",
    "                    skifile.saveTo(tmp_folder + '/galaxy.ski')\n",
    "            \n",
    "                    skirt = sm.Skirt()\n",
    "                    simulation = skirt.execute(tmp_folder + '/galaxy.ski', inDirPath=folder, outDirPath=folder, numThreadsPerProcess=4, console='brief') #brief\n",
    "\n",
    "                    if make_png:\n",
    "                        vis.makergbimages.makeConvolvedRGBImages(simulation, name='SDSS_U', contributions=[[SDSS_U, 1., 0, 0], [SDSS_U, 0, 1., 0],[SDSS_U, 0, 0, 1.]], fmin=1e-5, fmax=1e3)\n",
    "                        vis.makergbimages.makeConvolvedRGBImages(simulation, name='SDSS_G', contributions=[[SDSS_G, 1., 0, 0], [SDSS_G, 0, 1., 0],[SDSS_G, 0, 0, 1.]], fmin=1e-5, fmax=1e3)\n",
    "                        vis.makergbimages.makeConvolvedRGBImages(simulation, name='SDSS_R', contributions=[[SDSS_R, 1., 0, 0], [SDSS_R, 0, 1., 0],[SDSS_R, 0, 0, 1.]], fmin=1e-5, fmax=1e3)\n",
    "                        vis.makergbimages.makeConvolvedRGBImages(simulation, name='SDSS_I', contributions=[[SDSS_I, 1., 0, 0], [SDSS_I, 0, 1., 0],[SDSS_I, 0, 0, 1.]], fmin=1e-5, fmax=1e3)\n",
    "                        vis.makergbimages.makeConvolvedRGBImages(simulation, name='SDSS_Z', contributions=[[SDSS_Z, 1., 0, 0], [SDSS_Z, 0, 1., 0],[SDSS_Z, 0, 0, 1.]], fmin=1e-5, fmax=1e3)        \n",
    "            \n",
    "                        name_old = folder +  \"/galaxy_cube_total_SDSS_U.png \"\n",
    "                        name_new = folder +  '/SDSS_U_d_{:.1f}_theta_{:.2f}.png'.format(D, theta)\n",
    "                        subprocess.run(\"mv \"  + name_old + name_new, shell=True, text=True, capture_output=True)\n",
    "    \n",
    "                        name_old = folder +  \"/galaxy_cube_total_SDSS_G.png \"\n",
    "                        name_new = folder +  '/SDSS_G_d_{:.1f}_theta_{:.2f}.png'.format(D, theta)\n",
    "                        subprocess.run(\"mv \"  + name_old + name_new, shell=True, text=True, capture_output=True)\n",
    "    \n",
    "                        name_old = folder +  \"/galaxy_cube_total_SDSS_R.png \"\n",
    "                        name_new = folder +  '/SDSS_R_d_{:.1f}_theta_{:.2f}.png'.format(D, theta)\n",
    "                        subprocess.run(\"mv \"  + name_old + name_new, shell=True, text=True, capture_output=True)\n",
    "    \n",
    "                        name_old = folder +  \"/galaxy_cube_total_SDSS_I.png \"\n",
    "                        name_new = folder +  '/SDSS_I_d_{:.1f}_theta_{:.2f}.png'.format(D, theta)\n",
    "                        subprocess.run(\"mv \"  + name_old + name_new, shell=True, text=True, capture_output=True)\n",
    "    \n",
    "                        name_old = folder +  \"/galaxy_cube_total_SDSS_Z.png \"\n",
    "                        name_new = folder +  '/SDSS_Z_d_{:.1f}_theta_{:.2f}.png'.format(D, theta)\n",
    "                        subprocess.run(\"mv \"  + name_old + name_new, shell=True, text=True, capture_output=True)\n",
    "\n",
    "                    name_old = folder +  \"/galaxy_cube_total.fits \"\n",
    "                    name_new = folder +  '/SubID_{}_d_{:.1f}_theta_{:.2f}.fits'.format(ids, D, theta)\n",
    "                    subprocess.run(\"mv \"  + name_old + name_new, shell=True, text=True, capture_output=True)\n",
    "                    subprocess.run(\"rm \"  + folder + \"/galaxy_*.fits \", shell=True, text=True, capture_output=True)\n",
    "                    # -----------------------------------------------------------------------\n",
    "            \n",
    "                    # Let's use MARTINI\n",
    "                    \n",
    "                    xe_g  = gas_halo[2][ind_gas]\n",
    "                    rho_g = gas_halo[1][ind_gas] * (1e10) * (h**2) * U.Msun * np.power(U.kpc, -3)\n",
    "                    u_g   = gas_halo[5][ind_gas] # [km/s^2]  # unit conversion handled in T_g\n",
    "                    X_H_g = gas_halo_HI[ind_gas] # GFM_Metals[:,0] HI\n",
    "                    mu_g  = 4 / (1 + 3 * X_H_g + 4 * X_H_g * xe_g)\n",
    "                    gamma = 5.0 / 3.0  # see http://www.tng-project.org/data/docs/faq/#gen4\n",
    "                    T_g   = ((gamma - 1) * u_g / C.k_B.to_value(U.erg / U.K) * 1e10 * mu_g * U.K * C.m_p.to_value(U.g))\n",
    "                    m_g   = gas_halo_m[ind_gas] * U.Msun # Msun                    \n",
    "                    nH_g  = U.Quantity(rho_g * X_H_g / mu_g, dtype=np.float64) / C.m_p # cast to float64 to avoid underflow error (from martini)\n",
    "                                # In TNG_corrections I set f_neutral = 1 for particles with density\n",
    "                                # > .1cm^-3. Might be possible to do a bit better here, but HI & H2\n",
    "                                # tables for TNG will be available soon anyway.\n",
    "                    fatomic_g = atomic_frac(0, nH_g, T_g, rho_g, X_H_g, mu=mu_g, onlyA1=True, TNG_corrections=True)\n",
    "                    mHI_g  = m_g * X_H_g * fatomic_g        \n",
    "                    xyz_g  = particles[:,0:3] * U.kpc\n",
    "                    vxyz_g = particles[:,5:8] * U.km / U.s\n",
    "                    V_cell = (m_g / rho_g)  # Voronoi cell volume\n",
    "                    r_cell = np.power(3.0 * V_cell / 4.0 / np.pi, 1.0 / 3.0).to(U.kpc)\n",
    "                    # hsm_g has in mind a cubic spline that =0 at r=h, I think (from martini)\n",
    "                    hsm_g = 2.5 * r_cell * find_fwhm(CubicSplineKernel().kernel)\n",
    "            \n",
    "                    source = SPHSource(\n",
    "                        distance = D * U.Mpc,\n",
    "                        h        = h,\n",
    "                        T_g      = T_g,\n",
    "                        mHI_g    = mHI_g,\n",
    "                        xyz_g    = xyz_g,\n",
    "                        vxyz_g   = vxyz_g,\n",
    "                        hsm_g    = hsm_g,\n",
    "                        rotation = {\"rotmat\": rot_mat_martini} # This rotation need to be done because martini observer is on x axis\n",
    "                    )\n",
    "            \n",
    "                    datacube = DataCube(\n",
    "                        n_px_x     = 384,\n",
    "                        n_px_y     = 384,\n",
    "                        n_channels = 50,\n",
    "                        px_size    = 10.0 * U.arcsec,\n",
    "                        channel_width   = 16.0 * U.km * U.s**-1,\n",
    "                        velocity_centre = source.vsys,\n",
    "                        ra  = source.ra,\n",
    "                        dec = source.dec,\n",
    "                    )\n",
    "            \n",
    "                    M = Martini(source = source, datacube = datacube, beam = beam,\n",
    "                        noise = noise, spectral_model = spectral_model, sph_kernel = sph_kernel)\n",
    "            \n",
    "                    M.insert_source_in_cube(ncpu=1)\n",
    "                    M.add_noise()\n",
    "                    M.convolve_beam()\n",
    "                    M.write_fits(tmp_folder + 'HIEmission_SubID_{}_d_{:.1f}_theta_{:.2f}.fits'.format(ids, D, theta))\n",
    "\n",
    "                    if make_png:\n",
    "                        with fits.open(tmp_folder + 'HIEmission_SubID_{}_d_{:.1f}_theta_{:.2f}.fits'.format(ids, D, theta)) as f:\n",
    "                            cube_wcs   = WCS(f[0].header)\n",
    "                            flux_cube  = f[0].data * U.Unit(f[0].header[\"BUNIT\"])\n",
    "                            n_channels = cube_wcs.pixel_shape[cube_wcs.wcs.spec]\n",
    "                            vch        = np.array(cube_wcs.sub(axes=[3]).all_pix2world(np.arange(n_channels), 0))[\n",
    "                                0\n",
    "                            ] * U.Unit(cube_wcs.world_axis_units[cube_wcs.wcs.spec])\n",
    "                            vch = vch - source.vsys\n",
    "                \n",
    "                        # choose plotting units\n",
    "                        mom0_unit = U.Jy / U.beam\n",
    "                        mom1_unit = U.km / U.s\n",
    "                        mom2_unit = U.km / U.s\n",
    "                        \n",
    "                        rms  = np.std(flux_cube[:, :16, :16])  # noise in a corner patch where there is little signal\n",
    "                        clip = np.where(flux_cube > 5 * rms, 1, 0)\n",
    "                        np.seterr(all=\"ignore\")\n",
    "                \n",
    "                        mom0 = np.sum(flux_cube, axis=0)\n",
    "                        plt.imshow(mom0.to_value(mom0_unit), cmap=\"Greys\")\n",
    "                        plt.savefig(tmp_folder + 'HIMom0_d_{:.1f}_theta_{:.2f}.png'.format(D, theta), bbox_inches = 'tight')\n",
    "                \n",
    "                        mask = np.where(mom0 > 0.05 * U.Jy / U.beam, 1, np.nan)\n",
    "                        mom1 = np.sum(flux_cube * clip * vch[:, np.newaxis, np.newaxis], axis=0) / mom0\n",
    "                        plt.imshow(\n",
    "                            (mom1 * mask).to_value(mom1_unit),\n",
    "                            cmap = \"RdBu_r\",\n",
    "                            vmin = -np.nanmax(np.abs(mom1 * mask)).to_value(mom1_unit),\n",
    "                            vmax = np.nanmax(np.abs(mom1 * mask)).to_value(mom1_unit),\n",
    "                        )\n",
    "                        plt.savefig(tmp_folder + 'HIMom1_d_{:.1f}_theta_{:.2f}.png'.format(D, theta), bbox_inches = 'tight')\n",
    "                \n",
    "                        mom2 = np.sqrt(\n",
    "                            np.sum(\n",
    "                                flux_cube\n",
    "                                * clip\n",
    "                                * np.power(vch[:, np.newaxis, np.newaxis] - mom1[np.newaxis], 2),\n",
    "                                axis=0,\n",
    "                            )\n",
    "                            / mom0\n",
    "                        )\n",
    "                        plt.imshow((mom2 * mask).to_value(mom2_unit),cmap=\"magma\")        \n",
    "                        plt.savefig(tmp_folder + 'HIMom2_d_{:.1f}_theta_{:.2f}.png'.format(D, theta), bbox_inches = 'tight')\n",
    "                        #------------------------------------------------------------------------\n",
    "                \n",
    "                    # Move the images and remove the data\n",
    "                    subprocess.run(\"mv ../data/tmp/*.png \" + folder, shell=True, text=True, capture_output=True)\n",
    "                    subprocess.run(\"mv ../data/tmp/*SubID_{}*.fits \".format(ids) + folder, shell=True, text=True, capture_output=True)\n",
    "                    subprocess.run(\"rm ../data/tmp/*.* \", shell=True, text=True, capture_output=True)\n",
    "                    #-------------------------------------------------------------------------\n",
    "\n",
    "                    thetas.append(theta)\n",
    "                    dists.append(D)\n",
    "                    names.append('d_{:.1f}_theta_{:.2f}'.format(D, theta))\n",
    "            \n",
    "            gr.attrs['thetas'] = thetas\n",
    "            gr.attrs['dists'] = dists\n",
    "            gr.attrs['names'] = names\n",
    "            # Let's save a flag indicating that everything was done\n",
    "            gr.attrs['done'] = True\n",
    "            stop = time.time()\n",
    "            print('Subhalo {} analyzed in {:.2f} hours'.format(ids, (stop-start) / 3600))\n",
    "            ni += 1\n",
    "            if ni == nmax: break\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trying to make it parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_subhalo(combinaciones):\n",
    "    tmp_folder = 'tmp_' + str(current_process().name) + '/'\n",
    "    os.makedirs('../data/' + tmp_folder)\n",
    "    \n",
    "    theta = combinaciones[1]\n",
    "    D = combinaciones[0]\n",
    "    particles = np.copy(stars_particles)\n",
    "    # Rotate to be edge-on: (SKIRT is observing from z axis, i.e, it observe the plane x-y) \n",
    "    particles[:,0:3], particles[:,4:7] = rotate(particles = particles[:,0:3], velocities = particles[:,4:7], \n",
    "                                                theta = theta, rot_mat = rot_mat_AM) # This put the AM in the z-axis\n",
    "    particles[:,0:3], particles[:,4:7] = rotate(particles = particles[:,0:3], velocities = particles[:,4:7], \n",
    "                                                theta = theta) # This put the AM in the x-axis to be edge-on on skirt\n",
    "            \n",
    "    particles_old = particles[ind_old]\n",
    "    particles_new = particles[ind_new]\n",
    "    \n",
    "    if len(ind_old) > 0:\n",
    "        np.savetxt('../data/' + tmp_folder + '/stars_old.txt', particles_old, header = stars_old_header)\n",
    "        \n",
    "    if len(ind_new) > 0:\n",
    "        log10C = np.repeat(5, len(ind_new)).reshape(len(ind_new),1)\n",
    "        P = np.repeat(0.1, len(ind_new)).reshape(len(ind_new),1)\n",
    "        ccf = np.repeat(0.2, len(ind_new)).reshape(len(ind_new),1)\n",
    "        particles_new[:,7] = particles_new[:,7] / particles_new[:,9] * 1e9 # I dont know why we do this\n",
    "        \n",
    "        particles_new = np.hstack((particles_new, log10C, P, ccf))\n",
    "    \n",
    "        np.savetxt('../data/' + tmp_folder + '/stars_sb.txt', particles_new, header = stars_sb_header)\n",
    "\n",
    "    \n",
    "    # Rotate gas data to be edge-on\n",
    "    particles = np.copy(gas_particles)\n",
    "    \n",
    "    particles[:,0:3], particles[:,5:8] = rotate(particles = particles[:,0:3], velocities = particles[:,5:8], \n",
    "                                                theta = theta, rot_mat = rot_mat_AM) # This put the AM in the z-axis\n",
    "    particles[:,0:3], particles[:,5:8] = rotate(particles = particles[:,0:3], velocities = particles[:,5:8], \n",
    "                                                theta = theta) # This put the AM in the x-axis (to be edge-on in skirt)\n",
    "    \n",
    "    # Let's save the data\n",
    "    particles[:,3] = particles[:,3] * 1e-9 # Convert to [M_sun / Pc^3]\n",
    "    np.savetxt('../data/' + tmp_folder + '/gas.txt', particles, header = gas_header)\n",
    "    # ----------------------------------------------------------------\n",
    "\n",
    "    # Let's start with SKIRT\n",
    "    skifile = sm.SkiFile('template.ski')  \n",
    "    \n",
    "    skifile.setStringAttribute('.//VoronoiMeshMedium', 'minX', str(-Rmedium) + ' pc')\n",
    "    skifile.setStringAttribute('.//VoronoiMeshMedium', 'maxX', str(Rmedium) + ' pc')\n",
    "    skifile.setStringAttribute('.//VoronoiMeshMedium', 'minY', str(-Rmedium) + ' pc')\n",
    "    skifile.setStringAttribute('.//VoronoiMeshMedium', 'maxY', str(Rmedium) + ' pc')\n",
    "    skifile.setStringAttribute('.//VoronoiMeshMedium', 'minZ', str(-Rmedium) + ' pc')\n",
    "    skifile.setStringAttribute('.//VoronoiMeshMedium', 'maxZ', str(Rmedium) + ' pc')\n",
    "\n",
    "    skifile.setNumPrimaryPackets(2e7)\n",
    "    skifile.setStringAttribute('.//FrameInstrument', 'instrumentName', 'D_{:.1f}_theta_{:.2f}'.format(D, theta))\n",
    "    skifile.setStringAttribute('.//FrameInstrument', 'distance', str(D) + ' Mpc')\n",
    "    skifile.setStringAttribute('.//FrameInstrument', 'numPixelsX', str(n_px))\n",
    "    skifile.setStringAttribute('.//FrameInstrument', 'numPixelsY', str(n_px))\n",
    "    skifile.setStringAttribute('.//FrameInstrument', 'fieldOfViewX', str(100000) + ' pc')\n",
    "    skifile.setStringAttribute('.//FrameInstrument', 'fieldOfViewY', str(100000) + ' pc')\n",
    "    \n",
    "    skifile.saveTo('../data/' + tmp_folder + '/galaxy.ski')\n",
    "    subprocess.run(\"sed -i 's|stars_old|../../\" + tmp_folder + \"stars_old|g' \" + '../data/' + tmp_folder + 'galaxy.ski', shell=True, text=True, capture_output=True)\n",
    "\n",
    "    subprocess.run(\"sed -i 's|stars_sb|../../\" + tmp_folder + \"stars_sb|g' \" + '../data/' + tmp_folder + 'galaxy.ski', shell=True, text=True, capture_output=True)\n",
    "    \n",
    "    subprocess.run(\"sed -i 's|gas.txt|../../\" + tmp_folder + \"gas.txt|g' \" + '../data/' + tmp_folder + 'galaxy.ski', shell=True, text=True, capture_output=True)\n",
    "    \n",
    "    #subprocess.run(\"sed -i 's|dist|\" + str(D) + \"|g' \" + '../data/' + tmp_folder + 'galaxy.ski', shell=True, text=True, capture_output=True)\n",
    "\n",
    "    skirt = sm.Skirt()\n",
    "    simulation = skirt.execute('../data/' + tmp_folder + '/galaxy.ski', inDirPath=folder, outDirPath=folder, numThreadsPerProcess=4, console='brief') #brief\n",
    "\n",
    "    if make_png:\n",
    "        vis.makergbimages.makeConvolvedRGBImages(simulation, name='SDSS_U', contributions=[[SDSS_U, 1., 0, 0], [SDSS_U, 0, 1., 0],[SDSS_U, 0, 0, 1.]], fmin=1e-5, fmax=1e3)\n",
    "        vis.makergbimages.makeConvolvedRGBImages(simulation, name='SDSS_G', contributions=[[SDSS_G, 1., 0, 0], [SDSS_G, 0, 1., 0],[SDSS_G, 0, 0, 1.]], fmin=1e-5, fmax=1e3)\n",
    "        vis.makergbimages.makeConvolvedRGBImages(simulation, name='SDSS_R', contributions=[[SDSS_R, 1., 0, 0], [SDSS_R, 0, 1., 0],[SDSS_R, 0, 0, 1.]], fmin=1e-5, fmax=1e3)\n",
    "        vis.makergbimages.makeConvolvedRGBImages(simulation, name='SDSS_I', contributions=[[SDSS_I, 1., 0, 0], [SDSS_I, 0, 1., 0],[SDSS_I, 0, 0, 1.]], fmin=1e-5, fmax=1e3)\n",
    "        vis.makergbimages.makeConvolvedRGBImages(simulation, name='SDSS_Z', contributions=[[SDSS_Z, 1., 0, 0], [SDSS_Z, 0, 1., 0],[SDSS_Z, 0, 0, 1.]], fmin=1e-5, fmax=1e3)        \n",
    "\n",
    "        name_old = '../data/' + tmp_folder +  \"/galaxy_cube_total_SDSS_U.png \"\n",
    "        name_new = '../data/' + tmp_folder +  '/SDSS_U_d_{:.1f}_theta_{:.2f}.png'.format(D, theta)\n",
    "        subprocess.run(\"mv \"  + name_old + name_new, shell=True, text=True, capture_output=True)\n",
    "\n",
    "        name_old = '../data/' + tmp_folder +  \"/galaxy_cube_total_SDSS_G.png \"\n",
    "        name_new = '../data/' + tmp_folder +  '/SDSS_G_d_{:.1f}_theta_{:.2f}.png'.format(D, theta)\n",
    "        subprocess.run(\"mv \"  + name_old + name_new, shell=True, text=True, capture_output=True)\n",
    "\n",
    "        name_old = '../data/' + tmp_folder +  \"/galaxy_cube_total_SDSS_R.png \"\n",
    "        name_new = '../data/' + tmp_folder +  '/SDSS_R_d_{:.1f}_theta_{:.2f}.png'.format(D, theta)\n",
    "        subprocess.run(\"mv \"  + name_old + name_new, shell=True, text=True, capture_output=True)\n",
    "\n",
    "        name_old = '../data/' + tmp_folder +  \"/galaxy_cube_total_SDSS_I.png \"\n",
    "        name_new = '../data/' + tmp_folder +  '/SDSS_I_d_{:.1f}_theta_{:.2f}.png'.format(D, theta)\n",
    "        subprocess.run(\"mv \"  + name_old + name_new, shell=True, text=True, capture_output=True)\n",
    "\n",
    "        name_old = '../data/' + tmp_folder +  \"/galaxy_cube_total_SDSS_Z.png \"\n",
    "        name_new = '../data/' + tmp_folder +  '/SDSS_Z_d_{:.1f}_theta_{:.2f}.png'.format(D, theta)\n",
    "        subprocess.run(\"mv \"  + name_old + name_new, shell=True, text=True, capture_output=True)\n",
    "\n",
    "    name_old = '../data/' + tmp_folder +  \"/galaxy_cube_total.fits \"\n",
    "    name_new = '../data/' + tmp_folder +  '/SubID_{}_d_{:.1f}_theta_{:.2f}.fits'.format(ids, D, theta)\n",
    "    subprocess.run(\"mv \"  + name_old + name_new, shell=True, text=True, capture_output=True)\n",
    "\n",
    "    name_old = folder +  \"/galaxy_cube_total.fits \"\n",
    "    name_new = folder +  '/SubID_{}_d_{:.1f}_theta_{:.2f}.fits'.format(ids, D, theta)\n",
    "    subprocess.run(\"mv \"  + name_old + name_new, shell=True, text=True, capture_output=True)\n",
    "    subprocess.run(\"rm \"  + folder + \"/primary*.fits \", shell=True, text=True, capture_output=True)\n",
    "    subprocess.run(\"rm \"  + folder + \"/secondary*.fits \", shell=True, text=True, capture_output=True)\n",
    "    subprocess.run(\"rm \"  + folder + \"/*transparent*.fits \", shell=True, text=True, capture_output=True)\n",
    "    # -----------------------------------------------------------------------\n",
    "\n",
    "    # Let's use MARTINI\n",
    "    \n",
    "    xe_g  = gas_halo[2][ind_gas]\n",
    "    rho_g = gas_halo[1][ind_gas] * (1e10) * (h**2) * U.Msun * np.power(U.kpc, -3)\n",
    "    u_g   = gas_halo[5][ind_gas] # [km/s^2]  # unit conversion handled in T_g\n",
    "    X_H_g = gas_halo_HI[ind_gas] # GFM_Metals[:,0] HI\n",
    "    mu_g  = 4 / (1 + 3 * X_H_g + 4 * X_H_g * xe_g)\n",
    "    gamma = 5.0 / 3.0  # see http://www.tng-project.org/data/docs/faq/#gen4\n",
    "    T_g   = ((gamma - 1) * u_g / C.k_B.to_value(U.erg / U.K) * 1e10 * mu_g * U.K * C.m_p.to_value(U.g))\n",
    "    m_g   = gas_halo_m[ind_gas] * U.Msun # Msun                    \n",
    "    nH_g  = U.Quantity(rho_g * X_H_g / mu_g, dtype=np.float64) / C.m_p # cast to float64 to avoid underflow error (from martini)\n",
    "                # In TNG_corrections I set f_neutral = 1 for particles with density\n",
    "                # > .1cm^-3. Might be possible to do a bit better here, but HI & H2\n",
    "                # tables for TNG will be available soon anyway.\n",
    "    fatomic_g = atomic_frac(0, nH_g, T_g, rho_g, X_H_g, mu=mu_g, onlyA1=True, TNG_corrections=True)\n",
    "    mHI_g  = m_g * X_H_g * fatomic_g        \n",
    "    xyz_g  = particles[:,0:3] * U.kpc\n",
    "    vxyz_g = particles[:,5:8] * U.km / U.s\n",
    "    V_cell = (m_g / rho_g)  # Voronoi cell volume\n",
    "    r_cell = np.power(3.0 * V_cell / 4.0 / np.pi, 1.0 / 3.0).to(U.kpc)\n",
    "    # hsm_g has in mind a cubic spline that =0 at r=h, I think (from martini)\n",
    "    hsm_g = 2.5 * r_cell * find_fwhm(CubicSplineKernel().kernel)\n",
    "\n",
    "    source = SPHSource(\n",
    "        distance = D * U.Mpc,\n",
    "        h        = h,\n",
    "        T_g      = T_g,\n",
    "        mHI_g    = mHI_g,\n",
    "        xyz_g    = xyz_g,\n",
    "        vxyz_g   = vxyz_g,\n",
    "        hsm_g    = hsm_g,\n",
    "        rotation = {\"rotmat\": rot_mat_martini} # This rotation need to be done because martini observer is on x axis\n",
    "    )\n",
    "\n",
    "    datacube = DataCube(\n",
    "        n_px_x     = 384,\n",
    "        n_px_y     = 384,\n",
    "        n_channels = 50,\n",
    "        px_size    = 10.0 * U.arcsec,\n",
    "        channel_width   = 16.0 * U.km * U.s**-1,\n",
    "        velocity_centre = source.vsys,\n",
    "        ra  = source.ra,\n",
    "        dec = source.dec,\n",
    "    )\n",
    "\n",
    "    M = Martini(source = source, datacube = datacube, beam = beam,\n",
    "        noise = noise, spectral_model = spectral_model, sph_kernel = sph_kernel)\n",
    "\n",
    "    M.insert_source_in_cube(ncpu=1)\n",
    "    M.add_noise()\n",
    "    M.convolve_beam()\n",
    "    M.write_fits('../data/' + tmp_folder + 'HIEmission_SubID_{}_d_{:.1f}_theta_{:.2f}.fits'.format(ids, D, theta))\n",
    "\n",
    "    if make_png:\n",
    "        with fits.open('../data/' + tmp_folder + 'HIEmission_SubID_{}_d_{:.1f}_theta_{:.2f}.fits'.format(ids, D, theta)) as f:\n",
    "            cube_wcs   = WCS(f[0].header)\n",
    "            flux_cube  = f[0].data * U.Unit(f[0].header[\"BUNIT\"])\n",
    "            n_channels = cube_wcs.pixel_shape[cube_wcs.wcs.spec]\n",
    "            vch        = np.array(cube_wcs.sub(axes=[3]).all_pix2world(np.arange(n_channels), 0))[\n",
    "                0\n",
    "            ] * U.Unit(cube_wcs.world_axis_units[cube_wcs.wcs.spec])\n",
    "            vch = vch - source.vsys\n",
    "\n",
    "        # choose plotting units\n",
    "        mom0_unit = U.Jy / U.beam\n",
    "        mom1_unit = U.km / U.s\n",
    "        mom2_unit = U.km / U.s\n",
    "        \n",
    "        rms  = np.std(flux_cube[:, :16, :16])  # noise in a corner patch where there is little signal\n",
    "        clip = np.where(flux_cube > 5 * rms, 1, 0)\n",
    "        np.seterr(all=\"ignore\")\n",
    "\n",
    "        mom0 = np.sum(flux_cube, axis=0)\n",
    "        plt.imshow(mom0.to_value(mom0_unit), cmap=\"Greys\")\n",
    "        plt.savefig('../data/' + tmp_folder + 'HIMom0_d_{:.1f}_theta_{:.2f}.png'.format(D, theta), bbox_inches = 'tight')\n",
    "\n",
    "        mask = np.where(mom0 > 0.05 * U.Jy / U.beam, 1, np.nan)\n",
    "        mom1 = np.sum(flux_cube * clip * vch[:, np.newaxis, np.newaxis], axis=0) / mom0\n",
    "        plt.imshow(\n",
    "            (mom1 * mask).to_value(mom1_unit),\n",
    "            cmap = \"RdBu_r\",\n",
    "            vmin = -np.nanmax(np.abs(mom1 * mask)).to_value(mom1_unit),\n",
    "            vmax = np.nanmax(np.abs(mom1 * mask)).to_value(mom1_unit),\n",
    "        )\n",
    "        plt.savefig('../data/' + tmp_folder + 'HIMom1_d_{:.1f}_theta_{:.2f}.png'.format(D, theta), bbox_inches = 'tight')\n",
    "\n",
    "        mom2 = np.sqrt(\n",
    "            np.sum(\n",
    "                flux_cube\n",
    "                * clip\n",
    "                * np.power(vch[:, np.newaxis, np.newaxis] - mom1[np.newaxis], 2),\n",
    "                axis=0,\n",
    "            )\n",
    "            / mom0\n",
    "        )\n",
    "        plt.imshow((mom2 * mask).to_value(mom2_unit),cmap=\"magma\")        \n",
    "        plt.savefig('../data/' + tmp_folder + 'HIMom2_d_{:.1f}_theta_{:.2f}.png'.format(D, theta), bbox_inches = 'tight')\n",
    "        #------------------------------------------------------------------------\n",
    "\n",
    "    # Move the images and remove the data\n",
    "    subprocess.run(\"mv ../data/\" + tmp_folder + \"*.png \" + folder, shell=True, text=True, capture_output=True)\n",
    "    subprocess.run(\"mv ../data/\" + tmp_folder + \"*SubID_{}*.fits \".format(ids) + folder, shell=True, text=True, capture_output=True)\n",
    "    subprocess.run(\"rm ../data/\" + tmp_folder + \"*.* \", shell=True, text=True, capture_output=True)\n",
    "    #-------------------------------------------------------------------------\n",
    "\n",
    "    subprocess.run(\"rm -r ../data/\"  + tmp_folder, shell=True, text=True, capture_output=True)\n",
    "    \n",
    "    return theta, D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/u/m/mdelosri/MaDaMe/codes\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances = [4,10]\n",
    "rotations = [0, np.pi/2]\n",
    "nrot  = len(rotations)\n",
    "ndist = len(distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "combinaciones = list(product(distances, rotations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(4, 0), (4, 1.5707963267948966), (10, 0), (10, 1.5707963267948966)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combinaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/1886 [00:03<53:01,  1.69s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting the estimation of properties with subhalo particles for galaxy 114388\n"
     ]
    }
   ],
   "source": [
    "force_rerun = False\n",
    "make_png = False\n",
    "\n",
    "file = '../data/test.h5'\n",
    "\n",
    "nsubhalos = 2000\n",
    "\n",
    "rmax = 1000 # kPc\n",
    "# 0: ID\n",
    "# 1: central (1 if central, 0 if not)\n",
    "# 2: SubMass [Msun]\n",
    "# 3: SubSFR\n",
    "# 4: SubHMR [kPc]\n",
    "# 5: x [kPc]\n",
    "# 6: y [kPc]\n",
    "# 7: z [kPc]\n",
    "# 8: vx [km/s]\n",
    "# 9: vy [km/s]\n",
    "# 10: vz [km/s]\n",
    "# 11: SubVmax [km/s]\n",
    "# 12: SubVmaxR [kPc]\n",
    "# 13: SubHMRG [kPc] Comoving radius containing half of the mass of this Subhalo \n",
    "                    # split by Type (SubhaloMassType). Type 4 = gas\n",
    "# 14: costheta. Cosine of the angle between the angular momenta and the main axis\n",
    "                # of the inertia tensor.\n",
    "# 15: kappa_AM\n",
    "# 16: kappa_IT\n",
    "\n",
    "nmax = 20\n",
    "ni = 0\n",
    "with h5py.File(file, 'a') as data:\n",
    "    for i in tqdm(range(114,nsubhalos)):\n",
    "        ids = subhalos['results'][i]['id']\n",
    "        \n",
    "        # Let's load the data of the subhalos\n",
    "        sub_meta = get(subhalos['results'][i]['url'])    \n",
    "        # --------------------------------------------------------\n",
    "    \n",
    "        if 'SubID_' + str(ids) in data.keys():\n",
    "            flag_gr = False # This means that we do not have to analyze the group\n",
    "            print('Subhalo ' + str(ids) + ' already exists')\n",
    "            if not data['SubID_' + str(ids)].attrs['done']:\n",
    "                print('The analysis of the subhalo was not finished OK, so we have to do it again :(')\n",
    "                flag_gr = True # This means that we have to analyze the group\n",
    "                del data['SubID_' + str(ids)]\n",
    "                gr = data.create_group('SubID_' + str(ids))\n",
    "            if force_rerun:\n",
    "                flag_gr = True\n",
    "                print('Analysis forced to be run again!')\n",
    "        else:\n",
    "            if ids == get(get(sub_meta['related']['parent_halo'])['meta']['info'])['GroupFirstSub']: # Keep only central galaxies           \n",
    "                gr = data.create_group('SubID_' + str(ids))\n",
    "                flag_gr = True # This means that we have to analyze the group\n",
    "                gr.attrs['done'] = False\n",
    "            else:\n",
    "                flag_gr = False # This means that we do not have to analyze the group\n",
    "                    \n",
    "        if flag_gr:\n",
    "            gr.attrs['done'] = False\n",
    "            properties = np.zeros((1, 17))\n",
    "            start = time.time()\n",
    "            folder = '../data/TNGgalaxies/' + str(ids)\n",
    "            if not os.path.exists(folder):\n",
    "                os.makedirs(folder)\n",
    "            \n",
    "            # Let's save the main properties  ------------------------           \n",
    "            properties[0, 0] = ids   \n",
    "            gid = sub_meta['grnr'] # sub_meta['SubhaloGrNr']\n",
    "            properties[0, 1] = gid\n",
    "            properties[0, 2] = sub_meta['mass'] * 1e10 / h # [Msun] #sub_meta['SubhaloMass'] * 1e10 / h\n",
    "            properties[0, 3] = sub_meta['sfr'] # [Msun/yr] # sub_meta['SubhaloSFR']\n",
    "            properties[0, 4] = sub_meta['halfmassrad'] / h # [kPc]  # sub_meta['SubhaloHalfmassRad'] / h\n",
    "            properties[0, 5] = sub_meta['pos_x'] / h # [kPc]  # sub_meta['SubhaloPos'][0] / h\n",
    "            properties[0, 6] = sub_meta['pos_y'] / h # [kPc]  # sub_meta['SubhaloPos'][1] / h\n",
    "            properties[0, 7] = sub_meta['pos_z'] / h # [kPc]  # sub_meta['SubhaloPos'][2] / h\n",
    "            properties[0, 8] = sub_meta['vel_x'] # [km/s] # sub_meta['SubhaloVel'][0]\n",
    "            properties[0, 9] = sub_meta['vel_y'] # [km/s] # sub_meta['SubhaloVel'][1]\n",
    "            properties[0, 10] = sub_meta['vel_z'] # [km/s] # sub_meta['SubhaloVel'][2]\n",
    "            properties[0, 11] = sub_meta['vmax'] # [km/s] # sub_meta['SubhaloVmax']\n",
    "            properties[0, 12] = sub_meta['vmaxrad'] / h # [kPc] # sub_meta['SubhaloVmaxRad'] / h\n",
    "            properties[0, 13] = sub_meta['halfmassrad_stars'] / h # [kPc] # sub_meta['SubhaloHalfmassRadType'][4] / h\n",
    "    \n",
    "            # --------------------------------------------------------\n",
    "    \n",
    "            # Let's estimate properties with the particles of the subhalos\n",
    "            print('Starting the estimation of properties with subhalo particles for galaxy ' + str(ids))\n",
    "            sub_data_url = subhalos['results'][i]['url'] + 'vis.hdf5'\n",
    "            center_sub   = properties[0, 5:8]\n",
    "            velocity     = properties[0, 8:11]    \n",
    "            \n",
    "            stars_subhalo = get(subhalos['results'][i]['url'] + '/' + 'cutout.hdf5', \n",
    "                               {'stars':'Coordinates,GFM_InitialMass,GFM_Metallicity,GFM_StellarFormationTime,Masses,StellarHsml,Velocities'})\n",
    "            stars_c = stars_subhalo[0] / h\n",
    "            stars_v = stars_subhalo[6]\n",
    "            stars_m = stars_subhalo[4] * 1e10 / h\n",
    "            try:\n",
    "                gas_subhalo = get(subhalos['results'][i]['url'] + '/' + 'cutout.hdf5', \n",
    "                       {'gas':'coordinates,density,ElectronAbundance,GFM_Metallicity,GFM_Metals,InternalEnergy,masses,SubfindHsml,velocities'})\n",
    "    \n",
    "                gas_c   = gas_subhalo[0] / h\n",
    "                gas_v   = gas_subhalo[8]\n",
    "                gas_m   = gas_subhalo[6] * 1e10 / h\n",
    "                gas_HI  = gas_subhalo[4][:,0]\n",
    "                flag_gas = True\n",
    "            except:\n",
    "                print('Galaxy ' + str(ids) + ' have no gas')\n",
    "                flag_gas = False\n",
    "            dm_c    = get(subhalos['results'][i]['url'] + 'cutout.hdf5', {'dm':'Coordinates'})[0] / h\n",
    "            dm_v    = get(subhalos['results'][i]['url'] + 'cutout.hdf5', {'dm':'Velocities'})[0]\n",
    "    \n",
    "            # Let's move the coordinates if they are near the border\n",
    "            aux_ind = np.where( (stars_c[:, 0] - center_sub[0]) > (box_size / 2) )[0]\n",
    "            stars_c[aux_ind, 0] = stars_c[aux_ind, 0] - box_size\n",
    "            aux_ind = np.where( (center_sub[0] - stars_c[:, 0]) > (box_size / 2) )[0]\n",
    "            stars_c[aux_ind, 0] = stars_c[aux_ind, 0] + box_size\n",
    "            aux_ind = np.where( (stars_c[:, 1] - center_sub[1]) > (box_size / 2) )[0]\n",
    "            stars_c[aux_ind, 1] = stars_c[aux_ind, 1] - box_size\n",
    "            aux_ind = np.where( (center_sub[1] - stars_c[:, 1]) > (box_size / 2) )[0]\n",
    "            stars_c[aux_ind, 1] = stars_c[aux_ind, 1] + box_size\n",
    "            aux_ind = np.where( (stars_c[:, 2] - center_sub[2]) > (box_size / 2) )[0]\n",
    "            stars_c[aux_ind, 2] = stars_c[aux_ind, 2] - box_size\n",
    "            aux_ind = np.where( (center_sub[2] - stars_c[:, 2]) > (box_size / 2) )[0]\n",
    "            stars_c[aux_ind, 2] = stars_c[aux_ind, 2] + box_size\n",
    "            \n",
    "            if flag_gas:\n",
    "                aux_ind = np.where( (gas_c[:, 0] - center_sub[0]) > (box_size / 2) )[0]\n",
    "                gas_c[aux_ind, 0] = gas_c[aux_ind, 0] - box_size\n",
    "                aux_ind = np.where( (center_sub[0] - gas_c[:, 0]) > (box_size / 2) )[0]\n",
    "                gas_c[aux_ind, 0] = gas_c[aux_ind, 0] + box_size\n",
    "                aux_ind = np.where( (gas_c[:, 1] - center_sub[1]) > (box_size / 2) )[0]\n",
    "                gas_c[aux_ind, 1] = gas_c[aux_ind, 1] - box_size\n",
    "                aux_ind = np.where( (center_sub[1] - gas_c[:, 1]) > (box_size / 2) )[0]\n",
    "                gas_c[aux_ind, 1] = gas_c[aux_ind, 1] + box_size\n",
    "                aux_ind = np.where( (gas_c[:, 2] - center_sub[2]) > (box_size / 2) )[0]\n",
    "                gas_c[aux_ind, 2] = gas_c[aux_ind, 2] - box_size\n",
    "                aux_ind = np.where( (center_sub[2] - gas_c[:, 2]) > (box_size / 2) )[0]\n",
    "                gas_c[aux_ind, 2] = gas_c[aux_ind, 2] + box_size\n",
    "                \n",
    "            aux_ind = np.where( (dm_c[:, 0] - center_sub[0]) > (box_size / 2) )[0]\n",
    "            dm_c[aux_ind, 0] = dm_c[aux_ind, 0] - box_size\n",
    "            aux_ind = np.where( (center_sub[0] - dm_c[:, 0]) > (box_size / 2) )[0]\n",
    "            dm_c[aux_ind, 0] = dm_c[aux_ind, 0] + box_size\n",
    "            aux_ind = np.where( (dm_c[:, 1] - center_sub[1]) > (box_size / 2) )[0]\n",
    "            dm_c[aux_ind, 1] = dm_c[aux_ind, 1] - box_size\n",
    "            aux_ind = np.where( (center_sub[1] - dm_c[:, 1]) > (box_size / 2) )[0]\n",
    "            dm_c[aux_ind, 1] = dm_c[aux_ind, 1] + box_size\n",
    "            aux_ind = np.where( (dm_c[:, 2] - center_sub[2]) > (box_size / 2) )[0]\n",
    "            dm_c[aux_ind, 2] = dm_c[aux_ind, 2] - box_size\n",
    "            aux_ind = np.where( (center_sub[2] - dm_c[:, 2]) > (box_size / 2) )[0]\n",
    "            dm_c[aux_ind, 2] = dm_c[aux_ind, 2] + box_size\n",
    "            # --------------------------------------------------------\n",
    "            \n",
    "            # ------------------Let's center the particles -----------\n",
    "            stars_c = stars_c - center_sub\n",
    "            stars_v = stars_v - velocity\n",
    "            \n",
    "            dm_v = dm_v - velocity\n",
    "            dm_c = dm_c - center_sub\n",
    "            \n",
    "            if flag_gas:\n",
    "                gas_c = gas_c - center_sub\n",
    "                gas_v = gas_v - velocity\n",
    "            # --------------------------------------------------------\n",
    "                  \n",
    "            # Let's Compute the distance of each DM particle to the center and sum in radial bins\n",
    "            dist = np.linalg.norm(dm_c, axis=1)\n",
    "            M = np.array([len(np.where(np.array(dist) < R)[0]) * M_dm for R in R_bins])\n",
    "            if rmax == None: rmax = (3 * properties[0, 4]) # max radii for saving particles\n",
    "            ind_dm = np.where(np.array(dist) < rmax)[0] # for saving only close particles\n",
    "            # --------------------------------------------------------\n",
    "    \n",
    "            # Let's Compute the distance of each star particle to the center and sum in radial bins\n",
    "            dist = np.linalg.norm(stars_c, axis=1)\n",
    "            M_stars = np.array([np.sum( stars_m[np.where(np.array(dist) < R)[0]] ) for R in R_bins])\n",
    "            ind_stars = np.where(np.array(dist) < rmax)[0] # for saving only close particles\n",
    "            # --------------------------------------------------------\n",
    "    \n",
    "            # Compute the distance of each particle to the center and sum in radial bins\n",
    "            if flag_gas:\n",
    "                dist = np.linalg.norm(gas_c, axis=1)\n",
    "                M_gas = np.array([np.sum( gas_m[np.where(np.array(dist) < R)[0]] ) for R in R_bins])\n",
    "                ind_gas = np.where(np.array(dist) < rmax)[0] # for saving only close particles\n",
    "            # --------------------------------------------------------\n",
    "            \n",
    "            # Let's save the data of these profiles\n",
    "            gr.create_dataset('R_bins_sub', data = R_bins)\n",
    "            gr.create_dataset('M_DM_sub', data = M)\n",
    "            gr.create_dataset('M_stars_sub', data = M_stars)   \n",
    "            if flag_gas:\n",
    "                gr.create_dataset('M_gas_sub', data = M_gas)\n",
    "            # --------------------------------------------------------\n",
    "    \n",
    "            # Let's compute the rotation matrix taking into accunt the inertia tensor\n",
    "            rot_mat_IT, L_IT = compute_rot_mat_inertia(np.zeros(3), stars_c, stars_m, Rmax = 2 * properties[0, 13])\n",
    "            # --------------------------------------------------------\n",
    "    \n",
    "            # Let's compute the rotation matrix taking into accunt the angular momentum tensor\n",
    "            rot_mat_AM, L_AM = compute_rot_mat_angMom(np.zeros(3), stars_c, stars_v, stars_m, Rmax = 2 * properties[0, 13])\n",
    "            # --------------------------------------------------------\n",
    "    \n",
    "            # Let's rotate the coordiantes with AM\n",
    "            dm_c_rot_AM = dm_c @ rot_mat_AM\n",
    "            dm_v_rot_AM = dm_v @ rot_mat_AM\n",
    "            stars_c_rot_AM = stars_c @ rot_mat_AM\n",
    "            stars_v_rot_AM = stars_v @ rot_mat_AM\n",
    "            if flag_gas:\n",
    "                gas_c_rot_AM = gas_c @ rot_mat_AM\n",
    "                gas_v_rot_AM = gas_v @ rot_mat_AM\n",
    "    \n",
    "            L_AM_rot_AM = L_AM @ rot_mat_AM\n",
    "            L_IT_rot_AM = L_IT @ rot_mat_AM\n",
    "            # --------------------------------------------------------\n",
    "    \n",
    "            # Let's rotate the coordiantes with IT\n",
    "            dm_c_rot_IT = dm_c @ rot_mat_IT\n",
    "            dm_v_rotv = dm_v @ rot_mat_IT\n",
    "            stars_c_rot_IT = stars_c @ rot_mat_IT\n",
    "            stars_v_rot_IT = stars_v @ rot_mat_IT\n",
    "            if flag_gas:\n",
    "                gas_c_rot_IT = gas_c @ rot_mat_IT\n",
    "                gas_v_rot_IT = gas_v @ rot_mat_IT\n",
    "    \n",
    "            L_AM_rot_IT = L_AM @ rot_mat_IT\n",
    "            L_IT_rot_IT = L_IT @ rot_mat_IT\n",
    "            # --------------------------------------------------------\n",
    "    \n",
    "            # Let's aligendthe stars with the IT\n",
    "            x_stars_IT  = stars_c_rot_IT[:,0]\n",
    "            y_stars_IT  = stars_c_rot_IT[:,1]\n",
    "            z_stars_IT  = stars_c_rot_IT[:,2]\n",
    "            vx_stars_IT = stars_v_rot_IT[:,0]\n",
    "            vy_stars_IT = stars_v_rot_IT[:,1]\n",
    "            vz_stars_IT = stars_v_rot_IT[:,2]\n",
    "            # --------------------------------------------------------\n",
    "    \n",
    "    \n",
    "            # Let's move to cylindrical coordinates and the kinematical properties\n",
    "            r_stars_IT         = np.sqrt(x_stars_IT**2 + y_stars_IT**2)\n",
    "            phi_stars_IT       = np.arctan2(y_stars_IT, x_stars_IT)\n",
    "            jz_stars_IT        = x_stars_IT * vy_stars_IT - y_stars_IT * vx_stars_IT\n",
    "            Erot_stars_IT      = stars_m * (jz_stars_IT**2) / (r_stars_IT**2)\n",
    "            Ek_stars_IT        = stars_m * (vx_stars_IT**2 + vy_stars_IT**2 + vz_stars_IT**2)\n",
    "            kappa_stars_IT     = np.sum(Erot_stars_IT) / np.sum(Ek_stars_IT)\n",
    "            vphi_full_stars_IT = jz_stars_IT / r_stars_IT\n",
    "            # --------------------------------------------------------\n",
    "    \n",
    "    \n",
    "            # Now aligend the stars with the AM\n",
    "    \n",
    "            x_stars_AM  = stars_c_rot_AM[:,0]\n",
    "            y_stars_AM  = stars_c_rot_AM[:,1]\n",
    "            z_stars_AM  = stars_c_rot_AM[:,2]\n",
    "            vx_stars_AM = stars_v_rot_AM[:,0]\n",
    "            vy_stars_AM = stars_v_rot_AM[:,1]\n",
    "            vz_stars_AM = stars_v_rot_AM[:,2]\n",
    "            # --------------------------------------------------------\n",
    "    \n",
    "            # Let's move to cylindrical coordinates and the kinematical properties\n",
    "            r_stars_AM     = np.sqrt(x_stars_AM**2 + y_stars_AM**2)\n",
    "            phi_stars_AM   = np.arctan2(y_stars_AM, x_stars_AM)\n",
    "            jz_stars_AM    = x_stars_AM * vy_stars_AM - y_stars_AM * vx_stars_AM\n",
    "            Erot_stars_AM  = stars_m * (jz_stars_AM**2) / (r_stars_AM**2)\n",
    "            Ek_stars_AM    = stars_m * (vx_stars_AM**2 + vy_stars_AM**2 + vz_stars_AM**2)\n",
    "            kappa_stars_AM = np.sum(Erot_stars_AM) / np.sum(Ek_stars_AM)\n",
    "            vphi_full_stars_AM = jz_stars_AM / r_stars_AM\n",
    "            # --------------------------------------------------------\n",
    "    \n",
    "            # Let's save the main properties\n",
    "            properties[0, 14] = np.dot(L_IT, L_AM) / ( np.linalg.norm(L_IT) * np.linalg.norm(L_AM) )\n",
    "            properties[0, 15] = kappa_stars_AM\n",
    "            properties[0, 16] = kappa_stars_IT\n",
    "            # --------------------------------------------------------\n",
    "            gr.create_dataset('Props', data = properties[0,:])\n",
    "    \n",
    "            # Let's compute rotation curve with gas\n",
    "    \n",
    "            # Let's aligend the gas with the IT\n",
    "            if flag_gas:\n",
    "                x_gas_IT  = gas_c_rot_IT[:,0]\n",
    "                y_gas_IT  = gas_c_rot_IT[:,1]\n",
    "                z_gas_IT  = gas_c_rot_IT[:,2]\n",
    "                vx_gas_IT = gas_v_rot_IT[:,0]\n",
    "                vy_gas_IT = gas_v_rot_IT[:,1]\n",
    "                vz_gas_IT = gas_v_rot_IT[:,2]\n",
    "                # --------------------------------------------------------\n",
    "    \n",
    "                # Let's move to cylindrical coordinates and compute the kinematical properties\n",
    "                r_gas_IT         = np.sqrt(x_gas_IT**2 + y_gas_IT**2)\n",
    "                phi_gas_IT       = np.arctan2(y_gas_IT, x_gas_IT)\n",
    "                jz_gas_IT        = x_gas_IT * vy_gas_IT - y_gas_IT * vx_gas_IT\n",
    "                Erot_gas_IT      = gas_m * (jz_gas_IT**2) / (r_gas_IT**2)\n",
    "                Ek_gas_IT        = gas_m * (vx_gas_IT**2 + vy_gas_IT**2 + vz_gas_IT**2)\n",
    "                kappa_gas_IT     = np.sum(Erot_gas_IT) / np.sum(Ek_gas_IT)\n",
    "                vphi_full_gas_IT = jz_gas_IT / r_gas_IT\n",
    "                # --------------------------------------------------------\n",
    "    \n",
    "                # Now let's aligend the gas with the AM\n",
    "    \n",
    "                x_gas_AM  = gas_c_rot_AM[:,0]\n",
    "                y_gas_AM  = gas_c_rot_AM[:,1]\n",
    "                z_gas_AM  = gas_c_rot_AM[:,2]\n",
    "                vx_gas_AM = gas_v_rot_AM[:,0]\n",
    "                vy_gas_AM = gas_v_rot_AM[:,1]\n",
    "                vz_gas_AM = gas_v_rot_AM[:,2]\n",
    "    \n",
    "                # Let's move to cylindrical coordinates and compute the kinematical properties\n",
    "                r_gas_AM     = np.sqrt(x_gas_AM**2 + y_gas_AM**2)\n",
    "                phi_gas_AM   = np.arctan2(y_gas_AM, x_gas_AM)\n",
    "                jz_gas_AM    = x_gas_AM * vy_gas_AM - y_gas_AM * vx_gas_AM\n",
    "                Erot_gas_AM  = gas_m * (jz_gas_AM**2) / (r_gas_AM**2)\n",
    "                Ek_gas_AM    = gas_m * (vx_gas_AM**2 + vy_gas_AM**2 + vz_gas_AM**2)\n",
    "                kappa_gas_AM = np.sum(Erot_gas_AM) / np.sum(Ek_gas_AM)\n",
    "                vphi_full_gas_AM = jz_gas_AM / r_gas_AM\n",
    "                # --------------------------------------------------------\n",
    "    \n",
    "                # Let's compute the binned rotational curves and saved it\n",
    "                v_rot_gas_IT, bin_edges,_ = binned_statistic(r_gas_IT, np.abs(vphi_full_gas_IT), 'mean', bins = R_bins)\n",
    "                v_std_gas_IT,_,_ = binned_statistic(r_gas_IT, np.abs(vphi_full_gas_IT), 'std', bins = R_bins)\n",
    "                v_rot_gas_AM,_,_ = binned_statistic(r_gas_AM, np.abs(vphi_full_gas_AM), 'mean', bins = R_bins)\n",
    "                v_std_gas_AM,_,_ = binned_statistic(r_gas_AM, np.abs(vphi_full_gas_IT), 'std', bins = R_bins)\n",
    "    \n",
    "            v_rot_stars_IT, bin_edges,_  = binned_statistic(r_stars_IT, np.abs(vphi_full_stars_IT), 'mean', bins = R_bins)\n",
    "            v_std_stars_IT,_,_ = binned_statistic(r_stars_IT, np.abs(vphi_full_stars_IT), 'std', bins = R_bins)\n",
    "            v_rot_stars_AM,_,_ = binned_statistic(r_stars_AM, np.abs(vphi_full_stars_AM), 'mean', bins = R_bins)\n",
    "            v_std_stars_AM,_,_ = binned_statistic(r_stars_AM, np.abs(vphi_full_stars_AM), 'std', bins = R_bins)\n",
    "    \n",
    "            bin_width = (bin_edges[1] - bin_edges[0])\n",
    "            bin_centers = bin_edges[1:] - bin_width/2\n",
    "    \n",
    "            gr.create_dataset('R_bins_vels', data = bin_centers)\n",
    "            if flag_gas:\n",
    "                gr.create_dataset('V_rot_gas_IT', data = v_rot_gas_IT)\n",
    "                gr.create_dataset('V_std_gas_IT', data = v_std_gas_IT)\n",
    "                gr.create_dataset('V_rot_gas_AM', data = v_rot_gas_AM)\n",
    "                gr.create_dataset('V_std_gas_AM', data = v_std_gas_AM)\n",
    "            gr.create_dataset('V_rot_stars_IT', data = v_rot_stars_IT)\n",
    "            gr.create_dataset('V_std_stars_IT', data = v_std_stars_IT)\n",
    "            gr.create_dataset('V_rot_stars_AM', data = v_rot_stars_AM)\n",
    "            gr.create_dataset('V_std_stars_AM', data = v_std_stars_AM)\n",
    "            # ---------------------------------------------------------------------------------------\n",
    "    \n",
    "            # Let's estimate the real profiles taking into account the halo\n",
    "            print('Starting the estimation of properties with halo particles for galaxy ' + str(ids))\n",
    "    \n",
    "            # Let's load the DM particles of the halo to which the subhalo belongs\n",
    "            dm_halo = get('http://www.tng-project.org/api/TNG100-1/snapshots/99/halos/' + str(gid) + '/' + 'cutout.hdf5', {'dm':'coordinates'})[0] / h\n",
    "            \n",
    "            # ---------------------------------------------------------------------------------------\n",
    "    \n",
    "            # If the halo is near the border let's center it\n",
    "            aux_ind = np.where( (dm_halo[:, 0] - center_sub[0]) > (box_size / 2) )[0]\n",
    "            dm_halo[aux_ind, 0] = dm_halo[aux_ind, 0] - box_size\n",
    "            aux_ind = np.where( (center_sub[0] - dm_halo[:, 0]) > (box_size / 2) )[0]\n",
    "            dm_halo[aux_ind, 0] = dm_halo[aux_ind, 0] + box_size\n",
    "            aux_ind = np.where( (dm_halo[:, 1] - center_sub[1]) > (box_size / 2) )[0]\n",
    "            dm_halo[aux_ind, 1] = dm_halo[aux_ind, 1] - box_size\n",
    "            aux_ind = np.where( (center_sub[1] - dm_halo[:, 1]) > (box_size / 2) )[0]\n",
    "            dm_halo[aux_ind, 1] = dm_halo[aux_ind, 1] + box_size\n",
    "            aux_ind = np.where( (dm_halo[:, 2] - center_sub[2]) > (box_size / 2) )[0]\n",
    "            dm_halo[aux_ind, 2] = dm_halo[aux_ind, 2] - box_size\n",
    "            aux_ind = np.where( (center_sub[2] - dm_halo[:, 2]) > (box_size / 2) )[0]\n",
    "            dm_halo[aux_ind, 2] = dm_halo[aux_ind, 2] + box_size\n",
    "            # ---------------------------------------------------------------------------------------\n",
    "            # ----------------------Let's center de coords---------------------\n",
    "            dm_halo = dm_halo - center_sub\n",
    "            # -----------------------------------------------------------------\n",
    "            # Compute the distance of each particle to the center and sum in radial bins\n",
    "            dist = np.linalg.norm(dm_halo, axis=1)\n",
    "            M = np.array([len(np.where(np.array(dist) < R)[0]) * M_dm for R in R_bins])\n",
    "            # ---------------------------------------------------------------------------------------\n",
    "    \n",
    "            # Let's load the stars particles of the halo to which the subhalo belongs\n",
    "            \n",
    "            stars_halo = get('http://www.tng-project.org/api/TNG100-1/snapshots/99/halos/' + str(gid) + '/' + 'cutout.hdf5', \n",
    "                               {'stars':'Coordinates,GFM_InitialMass,GFM_Metallicity,GFM_StellarFormationTime,Masses,StellarHsml,Velocities'})\n",
    "            stars_halo_c = stars_halo[0] / h\n",
    "            stars_halo_m = stars_halo[4] * 1e10 / h\n",
    "            stars_halo_v = stars_halo[6]\n",
    "    \n",
    "            # ---------------------------------------------------------------------------------------\n",
    "    \n",
    "            # If the halo is near the border let's center it\n",
    "            aux_ind = np.where( (stars_halo_c[:, 0] - center_sub[0]) > (box_size / 2) )[0]\n",
    "            stars_halo_c[aux_ind, 0] = stars_halo_c[aux_ind, 0] - box_size\n",
    "            aux_ind = np.where( (center_sub[0] - stars_halo_c[:, 0]) > (box_size / 2) )[0]\n",
    "            stars_halo_c[aux_ind, 0] = stars_halo_c[aux_ind, 0] + box_size\n",
    "            aux_ind = np.where( (stars_halo_c[:, 1] - center_sub[1]) > (box_size / 2) )[0]\n",
    "            stars_halo_c[aux_ind, 1] = stars_halo_c[aux_ind, 1] - box_size\n",
    "            aux_ind = np.where( (center_sub[1] - stars_halo_c[:, 1]) > (box_size / 2) )[0]\n",
    "            stars_halo_c[aux_ind, 1] = stars_halo_c[aux_ind, 1] + box_size\n",
    "            aux_ind = np.where( (stars_halo_c[:, 2] - center_sub[2]) > (box_size / 2) )[0]\n",
    "            stars_halo_c[aux_ind, 2] = stars_halo_c[aux_ind, 2] - box_size\n",
    "            aux_ind = np.where( (center_sub[2] - stars_halo_c[:, 2]) > (box_size / 2) )[0]\n",
    "            stars_halo_c[aux_ind, 2] = stars_halo_c[aux_ind, 2] + box_size\n",
    "            \n",
    "            # ----------------------Let's center de coords---------------------\n",
    "            stars_halo_c = stars_halo_c - center_sub\n",
    "            stars_halo_v = stars_halo_v - velocity\n",
    "            # ---------------------------------------------------------------------------------------\n",
    "    \n",
    "            # Compute the distance of each particle to the center and sum in radial bins\n",
    "            dist = np.linalg.norm(stars_halo_c, axis=1)\n",
    "            M_stars = np.array([np.sum( stars_halo_m[np.where(np.array(dist) < R)[0]] ) for R in R_bins])\n",
    "            ind_stars = np.where(np.array(dist) < rmax)[0] # Keep only close particles\n",
    "            # ---------------------------------------------------------------------------------------\n",
    "    \n",
    "            # Let's load the stars particles of the halo to which the subhalo belongs\n",
    "            \n",
    "            gas_halo = get('http://www.tng-project.org/api/TNG100-1/snapshots/99/halos/' + str(gid) + '/' + 'cutout.hdf5', \n",
    "                           {'gas':'coordinates,density,ElectronAbundance,GFM_Metallicity,GFM_Metals,InternalEnergy,masses,SubfindHsml,velocities'})        \n",
    "            gas_halo_c = gas_halo[0] / h\n",
    "            gas_halo_m = gas_halo[6] * 1e10 / h\n",
    "            gas_halo_v = gas_halo[8]\n",
    "            gas_halo_HI = gas_halo[4][:,0]\n",
    "    \n",
    "            # ---------------------------------------------------------------------------------------\n",
    "    \n",
    "            # If the halo is near the border let's center it\n",
    "            aux_ind = np.where( (gas_halo_c[:, 0] - center_sub[0]) > (box_size / 2) )[0]\n",
    "            gas_halo_c[aux_ind, 0] = gas_halo_c[aux_ind, 0] - box_size\n",
    "            aux_ind = np.where( (center_sub[0] - gas_halo_c[:, 0]) > (box_size / 2) )[0]\n",
    "            gas_halo_c[aux_ind, 0] = gas_halo_c[aux_ind, 0] + box_size\n",
    "            aux_ind = np.where( (gas_halo_c[:, 1] - center_sub[1]) > (box_size / 2) )[0]\n",
    "            gas_halo_c[aux_ind, 1] = gas_halo_c[aux_ind, 1] - box_size\n",
    "            aux_ind = np.where( (center_sub[1] - gas_halo_c[:, 1]) > (box_size / 2) )[0]\n",
    "            gas_halo_c[aux_ind, 1] = gas_halo_c[aux_ind, 1] + box_size\n",
    "            aux_ind = np.where( (gas_halo_c[:, 2] - center_sub[2]) > (box_size / 2) )[0]\n",
    "            gas_halo_c[aux_ind, 2] = gas_halo_c[aux_ind, 2] - box_size\n",
    "            aux_ind = np.where( (center_sub[2] - gas_halo_c[:, 2]) > (box_size / 2) )[0]\n",
    "            gas_halo_c[aux_ind, 2] = gas_halo_c[aux_ind, 2] + box_size\n",
    "            # ----------------------Let's center de coords---------------------\n",
    "            gas_halo_c = gas_halo_c - center_sub        \n",
    "            gas_halo_v = gas_halo_v - velocity\n",
    "            # ---------------------------------------------------------------------------------------\n",
    "    \n",
    "            # Compute the distance of each particle to the center and sum in radial bins\n",
    "            dist = np.linalg.norm(gas_halo_c, axis=1)\n",
    "            M_gas = np.array([np.sum( gas_halo_m[np.where(np.array(dist) < R)[0]] ) for R in R_bins])\n",
    "    \n",
    "            ind_gas = np.where(np.array(dist) < rmax)[0] # Keep only close particles\n",
    "            gr.create_dataset('R_bins', data = R_bins)\n",
    "            gr.create_dataset('M_DM', data = M)\n",
    "            gr.create_dataset('M_stars', data = M_stars)   \n",
    "            gr.create_dataset('M_gas', data = M_gas)\n",
    "            # -------------------------------------------------------------------------------------\n",
    "    \n",
    "            # Let's read the particles and perform the corresponding rotations\n",
    "            stars_particles = stars_halo_c[ind_stars] # [kPc]\n",
    "            npart = len(stars_particles)\n",
    "            \n",
    "            aux = stars_halo[5][ind_stars] / h # Hsml [kPc]\n",
    "            stars_particles = np.hstack((stars_particles, aux.reshape(npart, 1)))\n",
    "            \n",
    "            aux = stars_halo_v[ind_stars] # Vels [km sqrt(a)/s]\n",
    "            stars_particles = np.hstack((stars_particles, aux))\n",
    "            \n",
    "            aux = stars_halo[1][ind_stars] * (1e10) / h # [Msun]\n",
    "            stars_particles = np.hstack((stars_particles, aux.reshape(npart, 1)))\n",
    "            \n",
    "            aux = stars_halo[2][ind_stars]\n",
    "            stars_particles = np.hstack((stars_particles, aux.reshape(npart, 1)))\n",
    "            \n",
    "            stars_SFT = stars_halo[3][ind_stars]\n",
    "            \n",
    "            stars_t0 = 13.8 * (1. - stars_SFT**1.5) + 1e-6\n",
    "            \n",
    "            stars_particles = np.hstack((stars_particles, stars_t0.reshape(npart, 1)))\n",
    "    \n",
    "            # Discard wind particles (definition from illustris documentation) \n",
    "            ind_wind = np.where(stars_SFT <= 0)[0]\n",
    "            if len(ind_wind) > 0:\n",
    "                stars_particles = np.delete(stars_particles, ind_wind, axis=0)\n",
    "                \n",
    "            # Compute the rotation matrix to alig the ang momenta to the z-axis\n",
    "            rot_mat_AM, L_AM = compute_rot_mat_angMom(np.zeros(3), stars_particles[:,0:3], stars_particles[:,4:7], stars_particles[:,8], Rmax = 200)\n",
    "            \n",
    "            # Separare old from young stars:\n",
    "            ind_old = np.where(stars_particles[:,9] > 1e-2)[0]        # from where do we get this condition???\n",
    "            ind_new = np.where(stars_particles[:,9] <= 1e-2)[0]\n",
    "\n",
    "            # Gas partciles\n",
    "                        \n",
    "            gas_particles = gas_halo_c[ind_gas] # [kPc]\n",
    "            gas_npart = len(gas_particles)\n",
    "            \n",
    "            aux = gas_halo[1][ind_gas] * (1e10) * (h**2) # [Msun / kPc^3]\n",
    "            gas_particles = np.hstack((gas_particles, aux.reshape(gas_npart, 1)))\n",
    "            \n",
    "            aux = gas_halo[3][ind_gas]\n",
    "            gas_particles = np.hstack((gas_particles, aux.reshape(gas_npart, 1)))\n",
    "            \n",
    "            aux = gas_halo_v[ind_gas] # Vels [km sqrt(a)/s]\n",
    "            gas_particles = np.hstack((gas_particles, aux))\n",
    "\n",
    "            if 'thetas' in gr.attrs: \n",
    "                thetas = gr.attrs['thetas']\n",
    "            else:\n",
    "                thetas = []\n",
    "            \n",
    "            if 'dists' in gr.attrs: \n",
    "                dists = gr.attrs['dists']\n",
    "            else:\n",
    "                dists = []\n",
    "            \n",
    "           # if 'names' in gr.attrs: \n",
    "           #     names = gr.attrs['names']\n",
    "           # else:\n",
    "           #     names = []\n",
    "\n",
    "            #for icomb in combinaciones:\n",
    "            #    analyze_subhalo(theta = icomb[0], D = icomb[1])\n",
    "\n",
    "            with Pool(processes=4) as pool:  # Número de procesos paralelos\n",
    "                resultados = pool.map(analyze_subhalo, combinaciones)\n",
    "            \n",
    "            gr.attrs['dists'] = dists\n",
    "            gr.attrs['thetas'] = thetas\n",
    "            gr.attrs['done'] = True\n",
    "            stop = time.time()\n",
    "            print('Subhalo {} analyzed in {:.2f} hours'.format(ids, (stop-start) / 3600))\n",
    "            ni += 1\n",
    "            if ni == nmax: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = h5py.File(file,'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
